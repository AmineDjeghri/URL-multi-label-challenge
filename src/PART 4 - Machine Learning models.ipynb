{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 3 - Machine Learning models\n",
    "#### Dans cette partie, nous allons diviser nos données, créer des features (OneHot, TF-IDF) et construire nos modèles (Baselines et modèles améliorés)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import spacy\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import regex\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "# nltk.download('stopwords')\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from unidecode import unidecode\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part-00000-1b8fcd71-6348-4510-a9dc-bdd7dcf82f2d-c000.snappy.parquet\n",
      "part-00001-1b8fcd71-6348-4510-a9dc-bdd7dcf82f2d-c000.snappy.parquet\n",
      "part-00002-1b8fcd71-6348-4510-a9dc-bdd7dcf82f2d-c000.snappy.parquet\n",
      "part-00003-1b8fcd71-6348-4510-a9dc-bdd7dcf82f2d-c000.snappy.parquet\n",
      "part-00004-1b8fcd71-6348-4510-a9dc-bdd7dcf82f2d-c000.snappy.parquet\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Path(\"../data/\").glob(\"*.parquet\") \n",
    "data = list(data)\n",
    "\n",
    "[print(parquet.name) for parquet in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((pd.read_parquet(parquet, engine='fastparquet') for parquet in data))\n",
    "pd.set_option(\"max_colwidth\", None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>target</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.cdiscount.com/bricolage/electricite/batterie-plomb-6v-4ah-ova51023e-pour-toplux/f-16614-ova2009927775303.html</td>\n",
       "      <td>[1831, 1751, 1192, 745, 1703]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.mystalk.net/profile/vitoriafcorrea</td>\n",
       "      <td>[847, 978, 582, 1381, 529]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.lequipe.fr/Tennis/TennisFicheJoueur1500000000003017.html</td>\n",
       "      <td>[20, 1077, 294]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://m.jeuxvideo.com/forums/42-32625-60180057-1-0-1-0-la-guilde-fourmi-legionnaire-recrute.htm</td>\n",
       "      <td>[381, 935, 1343, 622, 933]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://context.reverso.net/traduction/espagnol-francais/Para+ir</td>\n",
       "      <td>[692, 1265, 725, 1264, 1266]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67590</th>\n",
       "      <td>https://www.jeu-concours.biz/gagner-cafetiere-expresso.html</td>\n",
       "      <td>[1276, 65, 1113]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67591</th>\n",
       "      <td>https://www.sto.cx/book-186042-471.html</td>\n",
       "      <td>[608, 617, 1033, 220, 1021]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67592</th>\n",
       "      <td>http://jeu.info/solution/4-images-1-mot-niveau-2023-a-2060.html</td>\n",
       "      <td>[381, 925, 622, 1494, 937]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67593</th>\n",
       "      <td>https://grossesse.aufeminin.com/forum/levres-gonflees-et-accouchement-fd4242229</td>\n",
       "      <td>[638, 253, 419, 558, 401]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67594</th>\n",
       "      <td>https://www.conforama.fr/chambre-literie/literie/sommier-et-cadre-a-lattes/sommier-avec-coffre-160x200-cm-bultex-asteroid-coloris-bouleau/p/663906</td>\n",
       "      <td>[1367, 1372, 1368, 1370, 1369]</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67595 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      url  \\\n",
       "0                               https://www.cdiscount.com/bricolage/electricite/batterie-plomb-6v-4ah-ova51023e-pour-toplux/f-16614-ova2009927775303.html   \n",
       "1                                                                                                          https://www.mystalk.net/profile/vitoriafcorrea   \n",
       "2                                                                                    https://www.lequipe.fr/Tennis/TennisFicheJoueur1500000000003017.html   \n",
       "3                                                        http://m.jeuxvideo.com/forums/42-32625-60180057-1-0-1-0-la-guilde-fourmi-legionnaire-recrute.htm   \n",
       "4                                                                                        https://context.reverso.net/traduction/espagnol-francais/Para+ir   \n",
       "...                                                                                                                                                   ...   \n",
       "67590                                                                                         https://www.jeu-concours.biz/gagner-cafetiere-expresso.html   \n",
       "67591                                                                                                             https://www.sto.cx/book-186042-471.html   \n",
       "67592                                                                                     http://jeu.info/solution/4-images-1-mot-niveau-2023-a-2060.html   \n",
       "67593                                                                     https://grossesse.aufeminin.com/forum/levres-gonflees-et-accouchement-fd4242229   \n",
       "67594  https://www.conforama.fr/chambre-literie/literie/sommier-et-cadre-a-lattes/sommier-avec-coffre-160x200-cm-bultex-asteroid-coloris-bouleau/p/663906   \n",
       "\n",
       "                               target  day  \n",
       "0       [1831, 1751, 1192, 745, 1703]    4  \n",
       "1          [847, 978, 582, 1381, 529]    4  \n",
       "2                     [20, 1077, 294]    4  \n",
       "3          [381, 935, 1343, 622, 933]    4  \n",
       "4        [692, 1265, 725, 1264, 1266]    4  \n",
       "...                               ...  ...  \n",
       "67590                [1276, 65, 1113]    1  \n",
       "67591     [608, 617, 1033, 220, 1021]    1  \n",
       "67592      [381, 925, 622, 1494, 937]   16  \n",
       "67593       [638, 253, 419, 558, 401]    1  \n",
       "67594  [1367, 1372, 1368, 1370, 1369]   16  \n",
       "\n",
       "[67595 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_parse(url):\n",
    "    parse_result = urlparse(url)\n",
    "    result = [parse_result.scheme, parse_result.netloc, parse_result.path, parse_result.params, parse_result.query, parse_result.fragment]\n",
    "    return result\n",
    "\n",
    "df_parsed = pd.concat([df, \n",
    "                       pd.DataFrame(list(map(url_parse, df.url)),\n",
    "                    columns= ['scheme','netloc','path','params','quer','fragment'],\n",
    "                   index=df.url.index) \n",
    "                       ], axis=1)\n",
    "df_parsed.drop(['params', 'quer', 'fragment'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathTokenizer():\n",
    "    \"\"\" A simple class to tokenize the URL with a various combination of functions \n",
    "        \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.stemmer = SnowballStemmer(language='french')\n",
    "        self.stopwords = [unidecode(x) for x in stopwords.words('french')]\n",
    "        self.special_words = ['htm', 'php', 'aspx', 'html']\n",
    "\n",
    "    def _clean_text(self, text:str):\n",
    "        \"\"\" \n",
    "        remove the symbols from the a url  \n",
    "        \"\"\"\n",
    "        if isinstance(text, str):\n",
    "            regex = '(\\d+|[A-Z][a-z]*)|[+;,\\s.!:\\'/_%#&$@?~*]|-'\n",
    "            t = list(filter(None, re.split(regex, text)))\n",
    "            return t\n",
    "        else:\n",
    "            raise TypeError(\"text must be list\")\n",
    "    \n",
    "    def _lowercase_text(self, tokens: list):\n",
    "        if isinstance(tokens, list):\n",
    "            return [t.lower() for t in tokens]\n",
    "        else:\n",
    "            raise TypeError(\"text must be list\")\n",
    "    \n",
    "    def _remove_stopwords(self, tokens:list):\n",
    "        if isinstance(tokens, list):\n",
    "            return [t for t in tokens if t not in self.stopwords]\n",
    "        else:\n",
    "            raise TypeError(\"tokens must be a list\")\n",
    "            \n",
    "    def _remove_single(self, tokens: list):\n",
    "        \"remove single elements from list \"\n",
    "        if isinstance(tokens, list):\n",
    "            return [t for t in tokens if len(t)>1]\n",
    "        else:\n",
    "            raise TypeError(\"tokens must be a list\")\n",
    "            \n",
    "    def _remove_specials(self, tokens:list):\n",
    "        if isinstance(tokens, list):\n",
    "            return [t for t in tokens if t not in self.special_words]\n",
    "        else:\n",
    "            raise TypeError(\"tokens must be a list\")\n",
    "    \n",
    "    def _remove_numbers(self, tokens:list):\n",
    "        if isinstance(tokens, list):\n",
    "            # return [x for x in text if not any(x1.isdigit() for x1 in x)]\n",
    "            return [t for t in tokens if not t.isdigit()]\n",
    "        else:\n",
    "            raise TypeError(\"tokens must be a list\") \n",
    "            \n",
    "    def _stem_text(self, tokens:list):\n",
    "        if isinstance(tokens, list):        \n",
    "            return [self.stemmer.stem(token) for token in tokens]\n",
    "        else:\n",
    "            raise TypeError(\"tokens must be a list\")        \n",
    "        \n",
    "    def _tokenize_text(self, text:str):\n",
    "        return word_tokenize(text, language='french')\n",
    "        \n",
    "    def _join_words(self, text:list):\n",
    "        \"\"\" build a sentence from a list of words and separates them with a sapce\"\"\"\n",
    "        return \" \".join(text)\n",
    "    \n",
    "    def _split_words(self, text:str):\n",
    "        return text.split(' ')\n",
    "    \n",
    "    def clean_df(self, df_column, funcs_list):\n",
    "        \"Apply multiple functions on a column of a dataframe\"\n",
    "        for func in funcs_list:\n",
    "            df_column = df_column.apply(func)\n",
    "        return df_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_netloc(netloc:str):\n",
    "    splited_netloc = netloc.rsplit('.', 2)\n",
    "    if len(splited_netloc) == 2:\n",
    "        splited_netloc.insert(0, \"www\")\n",
    "    return splited_netloc\n",
    "\n",
    "df_parsed_2 = pd.concat([df_parsed, \n",
    "                       pd.DataFrame(list(map(split_netloc, df_parsed.netloc)),\n",
    "                    columns= ['sous_domaine','domaine','top_domaine'],\n",
    "                   index=df_parsed.netloc.index) \n",
    "                       ], axis=1)\n",
    "\n",
    "path_tokenizer = PathTokenizer()\n",
    "\n",
    "funcs = [path_tokenizer._clean_text, path_tokenizer._remove_numbers, path_tokenizer._remove_single, path_tokenizer._stem_text,\n",
    "        path_tokenizer._lowercase_text, path_tokenizer._remove_specials, path_tokenizer._remove_stopwords ]\n",
    "\n",
    "df_parsed_2['tokens_path'] = path_tokenizer.clean_df(df_parsed_2.path, funcs)\n",
    "\n",
    "df_cleaned = df_parsed_2.drop(['url', 'path', 'scheme', 'netloc'], axis=1)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "targets_encoded = pd.DataFrame(mlb.fit_transform(df_cleaned.target),\n",
    "                   columns=mlb.classes_,\n",
    "                   index=df_cleaned.target.index)\n",
    "df_cleaned_2 = pd.concat([df_cleaned, targets_encoded], axis=1)\n",
    "df_cleaned_3 = df_cleaned_2.copy(deep=True).drop(columns=['target'])\n",
    "df_cleaned_3[\"tokens_path\"] = df_cleaned_3.tokens_path.apply(path_tokenizer._join_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>sous_domaine</th>\n",
       "      <th>domaine</th>\n",
       "      <th>top_domaine</th>\n",
       "      <th>tokens_path</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1003</th>\n",
       "      <th>...</th>\n",
       "      <th>990</th>\n",
       "      <th>991</th>\n",
       "      <th>992</th>\n",
       "      <th>993</th>\n",
       "      <th>994</th>\n",
       "      <th>995</th>\n",
       "      <th>996</th>\n",
       "      <th>997</th>\n",
       "      <th>998</th>\n",
       "      <th>999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>www</td>\n",
       "      <td>cdiscount</td>\n",
       "      <td>com</td>\n",
       "      <td>bricolag electricit batter plomb ah ova toplux ova</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>www</td>\n",
       "      <td>mystalk</td>\n",
       "      <td>net</td>\n",
       "      <td>profil vitoriafcorr</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>www</td>\n",
       "      <td>lequipe</td>\n",
       "      <td>fr</td>\n",
       "      <td>ten ten fich joueur</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>jeuxvideo</td>\n",
       "      <td>com</td>\n",
       "      <td>forum guild fourm legionnair recrut</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>context</td>\n",
       "      <td>reverso</td>\n",
       "      <td>net</td>\n",
       "      <td>traduct espagnol franc ir</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1908 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   day sous_domaine    domaine top_domaine  \\\n",
       "0    4          www  cdiscount         com   \n",
       "1    4          www    mystalk         net   \n",
       "2    4          www    lequipe          fr   \n",
       "3    4            m  jeuxvideo         com   \n",
       "4    4      context    reverso         net   \n",
       "\n",
       "                                          tokens_path  100  1000  1001  1002  \\\n",
       "0  bricolag electricit batter plomb ah ova toplux ova    0     0     0     0   \n",
       "1                                 profil vitoriafcorr    0     0     0     0   \n",
       "2                                 ten ten fich joueur    0     0     0     0   \n",
       "3                 forum guild fourm legionnair recrut    0     0     0     0   \n",
       "4                           traduct espagnol franc ir    0     0     0     0   \n",
       "\n",
       "   1003  ...  990  991  992  993  994  995  996  997  998  999  \n",
       "0     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "1     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "2     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "3     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "4     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 1908 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned_3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50696, 4)\n",
      "(16899, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>domaine</th>\n",
       "      <th>top_domaine</th>\n",
       "      <th>tokens_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4625</th>\n",
       "      <td>11</td>\n",
       "      <td>reverso</td>\n",
       "      <td>net</td>\n",
       "      <td>traduct franc italien nombreux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279</th>\n",
       "      <td>14</td>\n",
       "      <td>reverso</td>\n",
       "      <td>net</td>\n",
       "      <td>conjugacion franc verbo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62554</th>\n",
       "      <td>9</td>\n",
       "      <td>augsburger-allgemeine</td>\n",
       "      <td>de</td>\n",
       "      <td>donauwoerth eurocopt hebt nach marseil ab id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30717</th>\n",
       "      <td>9</td>\n",
       "      <td>societe</td>\n",
       "      <td>com</td>\n",
       "      <td>dirig xavi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45182</th>\n",
       "      <td>4</td>\n",
       "      <td>cdiscount</td>\n",
       "      <td>com</td>\n",
       "      <td>high tech accessoir android tv box max boiti tv gb gb auc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29598</th>\n",
       "      <td>9</td>\n",
       "      <td>morgenpost</td>\n",
       "      <td>de</td>\n",
       "      <td>politik articl bundeswehr kaempft gegen borkenkaef politik spricht von katastroph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54058</th>\n",
       "      <td>16</td>\n",
       "      <td>momes</td>\n",
       "      <td>net</td>\n",
       "      <td>comptin comptin march</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45062</th>\n",
       "      <td>4</td>\n",
       "      <td>jeuxvideo</td>\n",
       "      <td>com</td>\n",
       "      <td>forum sondag pir arme jeu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11128</th>\n",
       "      <td>16</td>\n",
       "      <td>marmiton</td>\n",
       "      <td>org</td>\n",
       "      <td>recet recet avis brick chevr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9078</th>\n",
       "      <td>3</td>\n",
       "      <td>linternaute</td>\n",
       "      <td>fr</td>\n",
       "      <td>dictionnair fr synonym forc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50696 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       day                domaine top_domaine  \\\n",
       "4625    11                reverso         net   \n",
       "6279    14                reverso         net   \n",
       "62554    9  augsburger-allgemeine          de   \n",
       "30717    9                societe         com   \n",
       "45182    4              cdiscount         com   \n",
       "...    ...                    ...         ...   \n",
       "29598    9             morgenpost          de   \n",
       "54058   16                  momes         net   \n",
       "45062    4              jeuxvideo         com   \n",
       "11128   16               marmiton         org   \n",
       "9078     3            linternaute          fr   \n",
       "\n",
       "                                                                             tokens_path  \n",
       "4625                                                      traduct franc italien nombreux  \n",
       "6279                                                             conjugacion franc verbo  \n",
       "62554                                       donauwoerth eurocopt hebt nach marseil ab id  \n",
       "30717                                                                         dirig xavi  \n",
       "45182                          high tech accessoir android tv box max boiti tv gb gb auc  \n",
       "...                                                                                  ...  \n",
       "29598  politik articl bundeswehr kaempft gegen borkenkaef politik spricht von katastroph  \n",
       "54058                                                              comptin comptin march  \n",
       "45062                                                          forum sondag pir arme jeu  \n",
       "11128                                                       recet recet avis brick chevr  \n",
       "9078                                                         dictionnair fr synonym forc  \n",
       "\n",
       "[50696 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "y = df_cleaned_3.iloc[:, 5:]\n",
    "x = df_cleaned_3.iloc[:, : 5].drop(['sous_domaine'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.25)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réduction de la dimension des labels\n",
    "Nous avons 1903 labels pour notre target ce qui reprensente un nombre assez elevé pour de la classification multi-label.\n",
    "Nous allons donc effectuer une réduction sur l'espace de dimension des labels.\n",
    "Plusieurs algorithmes existent pour la réduction de l'espace des labels: compressed sensing (CS) et la  Principal Label Space Transformation (PLST) qui est l'équivalente du PCA sur les features. Egalement des techniques d'embeddings entre targets\n",
    "Contrairement à ces techniques qui sont indépendentes de nos entrées, il en existe aussi d'autres qui le sont comme par exemple la CPLST ( Conditional Principal Label Space Transformation ) \n",
    "\n",
    "Un autre moyen serait d'essayer d'utiliser une approches par embeddings.\n",
    "\n",
    "Egalement, une autre approche serait d'utiliser \n",
    "\n",
    "Pour la classification multi-label, il existe une librarie nommée `scikit-multilearn` qui s'appuie sur la librarie scikit-learn. Elle contient aussi un wrapper autour de  MEKA qui propose une implémentation des méthodes d'apprentissage et d'évaluation multi-labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction des features à partir du path\n",
    "Différentes approches peuvent etre utilisées sur la colonne path:\n",
    "#### L'utilisation de TF-IDF \n",
    "- TF-IDF: refléte l'importance d'un mot pour un document dans une collection (corpus) mais ne prend pas en compte le sens sémantique des mots. TF signifie la probabilité d'occurrence d'un mot dans une phrase.\n",
    "- TF-IDF donne plus d'importance aux mots qui apparaissent moins fréquemment dans l'ensemble du corpus et donne également de l'importance aux mots les plus fréquents qui apparaissent dans chaque donnée.\n",
    "\n",
    "Nous testerons les featurizations suivantes:\n",
    "- TF-IDF: unigrams, bigrams, trigrams et word n-grams.\n",
    "- TF-IDF based character: unigrams, bigrams, trigrams. (considérer une séquence de caractères plutôt qu'une séquence de mots)\n",
    "\n",
    "\n",
    "#### L'utilisation des Embeddings (word2vec)\n",
    "- Word2vec est l'un des modèle de l'état de l'art pour les embeddings.  Il permet de convertir du texte en vecteurs numériques tout en préservantles relations sémantiques entre les mots.\n",
    "- vecteur de 300 dimensions \n",
    "\n",
    "#### L'utilisation d'une combinaison de TF-IDF et moyenne des Embeddings:\n",
    "Nombiner les n-grammes de caractères avec les vecteurs obtenus avec Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.explode('target')['target'].unique()\n",
    "labels\n",
    "len_labels = len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_labels = df.explode('target')['target'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_labels[count_labels == 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5006    3\n",
       "5179    3\n",
       "5635    3\n",
       "5486    3\n",
       "897     3\n",
       "1251    3\n",
       "5086    3\n",
       "5439    3\n",
       "5811    3\n",
       "5512    3\n",
       "5350    3\n",
       "699     3\n",
       "1830    3\n",
       "5867    3\n",
       "5772    3\n",
       "1592    3\n",
       "5627    3\n",
       "5227    3\n",
       "1378    3\n",
       "5450    3\n",
       "5445    3\n",
       "5864    3\n",
       "5026    3\n",
       "5637    3\n",
       "1257    3\n",
       "5169    3\n",
       "5636    3\n",
       "5716    3\n",
       "1575    3\n",
       "5581    3\n",
       "1837    3\n",
       "5507    3\n",
       "5177    3\n",
       "5092    3\n",
       "1666    3\n",
       "1520    3\n",
       "1016    3\n",
       "5131    3\n",
       "5576    3\n",
       "1886    3\n",
       "5568    3\n",
       "1840    3\n",
       "1060    3\n",
       "1744    3\n",
       "5483    3\n",
       "5091    3\n",
       "1678    3\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_labels[count_labels == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191.  36.  50.]\n",
      " [189.  37.  52.]\n",
      " [193.  38.  58.]\n",
      " [162.  35.  62.]\n",
      " [189.  35.  46.]\n",
      " [182.  36.  56.]\n",
      " [211.  38.  56.]\n",
      " [167.  34.  60.]\n",
      " [176.  31.  74.]\n",
      " [154.  33.  56.]\n",
      " [169.  34.  50.]\n",
      " [166.  33.  52.]\n",
      " [154.  34.  64.]\n",
      " [247.  46.  50.]\n",
      " [193.  36.  46.]\n",
      " [202.  37.  62.]\n",
      " [176.  37.  54.]\n",
      " [157.  32.  52.]\n",
      " [156.  33.  54.]\n",
      " [138.  33.  68.]]\n",
      "prdicted [[176.16484296  35.0548407   57.09000136]\n",
      " [188.91063061  37.56282467  54.90134304]\n",
      " [189.95342365  37.70903167  53.32601213]\n",
      " [183.12565674  35.75756513  55.379517  ]\n",
      " [173.71664101  34.19041225  56.86332544]\n",
      " [188.24891043  37.14988781  55.05551172]\n",
      " [185.98328384  36.4924979   55.17764814]\n",
      " [181.88881353  35.85249351  56.12524172]\n",
      " [161.29353272  31.59790187  59.28698315]\n",
      " [168.78382349  35.14015097  55.24608816]\n",
      " [177.5849981   34.49820472  55.9858454 ]\n",
      " [167.04250441  33.56470984  57.49566251]\n",
      " [164.54944009  32.94682891  58.00146809]\n",
      " [201.52146372  39.84126139  52.67320665]\n",
      " [193.03036486  37.82070841  54.07885873]\n",
      " [167.98119562  33.84093336  57.34729124]\n",
      " [195.59664387  38.32927601  53.8331891 ]\n",
      " [160.37561585  32.05130197  59.36513952]\n",
      " [158.91979326  31.51181739  59.36551594]\n",
      " [187.32842123  37.0873515   55.40215097]]\n",
      "0.29687777631731227\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_linnerud\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "X, y = load_linnerud(return_X_y=True)\n",
    "print(y)\n",
    "\n",
    "clf = MultiOutputRegressor(Ridge(random_state=123)).fit(X, y)\n",
    "clf.predict(X[[0]])\n",
    "print(\"prdicted\",clf.predict(X) )\n",
    "from numpy import absolute\n",
    "n_scores = absolute(clf.score(X, y))\n",
    "print(n_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import (KNeighborsClassifier,\n",
    "                               NeighborhoodComponentsAnalysis)\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "categorical_features = [\"day\",\"domaine\",\"top_domaine\"]\n",
    "\n",
    "tfidf = TfidfVectorizer(min_df=0)\n",
    "vectorizer = TfidfVectorizer(min_df=0.00009, smooth_idf=True, norm=\"l2\", tokenizer = lambda x: x.split(\" \"), sublinear_tf=False, ngram_range=(1,1))\n",
    "\n",
    "transformer = ColumnTransformer([ ('categorical', OneHotEncoder(sparse=False, handle_unknown = \"ignore\"), categorical_features),\n",
    "                            (\"vectorizer\", vectorizer, \"tokens_path\"),\n",
    "                         ], remainder=\"passthrough\")\n",
    "\n",
    "X_train_multilabel = transformer.fit_transform(X_train)\n",
    "X_test_multilabel = transformer.transform(X_test)\n",
    "y_train_multilabel = y_train \n",
    "y_test_multilabel = y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int32"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795380660263765\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.sparse import random as sparse_random\n",
    "\n",
    "svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "svd.fit(y_train)\n",
    "print(svd.explained_variance_ratio_.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.16698157e-03  2.02205174e-01 -1.51674001e-03 ... -9.06461679e-02\n",
      "  -7.46545276e-02  1.07088520e-01]\n",
      " [ 3.29729426e-04  5.68230880e-04  2.30665080e-03 ...  6.64352325e-02\n",
      "   5.20180074e-02  2.03716402e-02]\n",
      " [ 8.08941869e-04  4.15118428e-03  1.65159303e-02 ... -1.73589724e-02\n",
      "   7.71876700e-02  6.36869989e-02]\n",
      " ...\n",
      " [ 1.71505005e-04  2.94716032e-04  9.24831989e-04 ... -8.14931007e-02\n",
      "   4.41209369e-02 -9.26041634e-02]\n",
      " [ 1.32073693e-03  7.05162267e-04  3.08925341e-03 ...  7.68610501e-04\n",
      "   9.07694964e-03 -9.02635115e-03]\n",
      " [ 5.26857327e-04  2.36930098e-03  3.84579757e-03 ...  5.97734134e-02\n",
      "   2.39768145e-02 -1.23545101e-02]]\n",
      "[[ 6.43451589e-04  2.24598175e-04  3.19885197e-04 ...  4.87054545e-03\n",
      "  -1.48145589e-02  1.23834718e-02]\n",
      " [ 1.00996203e-03  4.89659300e-03  3.56150823e-03 ... -6.84465562e-02\n",
      "   8.60469400e-03  1.06722370e-01]\n",
      " [ 1.78608895e-03  3.01563255e-03  3.03268881e-03 ...  4.63070562e-03\n",
      "   7.07963553e-03  8.13964791e-03]\n",
      " ...\n",
      " [ 3.67130314e-04  8.79875142e-04  2.47790795e-03 ...  3.96100001e-02\n",
      "   2.93751395e-02 -4.09020709e-02]\n",
      " [ 1.80343679e-04  1.29112183e-04  4.58136788e-03 ...  1.20364115e-02\n",
      "  -4.62954708e-03  1.55254747e-03]\n",
      " [ 1.98464795e-03  2.03638096e-03  1.60778608e-01 ...  8.21808559e-03\n",
      "   3.44284970e-02 -2.32618482e-02]]\n"
     ]
    }
   ],
   "source": [
    "y_train_pca = svd.transform(y_train)\n",
    "y_test_pca = svd.transform(y_test)\n",
    "print(y_train_pca)\n",
    "print(y_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from numpy import absolute\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "# define dataset\n",
    "\n",
    "# define base model\n",
    "model = LinearSVR()\n",
    "# define the direct multioutput wrapper model\n",
    "wrapper = MultiOutputRegressor(model)\n",
    "# define the evaluation procedure\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(wrapper, X_train_multilabel, y_train_pca, scoring='neg_mean_absolute_error', n_jobs=-1)\n",
    "# force the scores to be positive\n",
    "n_scores = absolute(n_scores)\n",
    "# summarize performance\n",
    "print('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Pipeline.fit does not accept the with_mean parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-d75311624617>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;31m# Fit the method's model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_multilabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_multilabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_mean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Fit a nearest neighbor classifier on the embedded training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \"\"\"\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         with _print_elapsed_time('Pipeline',\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_check_fit_params\u001b[1;34m(self, **fit_params)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'__'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    244\u001b[0m                     \u001b[1;34m\"Pipeline.fit does not accept the {} parameter. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                     \u001b[1;34m\"You can pass parameters to specific steps of your \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Pipeline.fit does not accept the with_mean parameter. You can pass parameters to specific steps of your pipeline using the stepname__parameter format, e.g. `Pipeline.fit(X, y, logisticregression__sample_weight=sample_weight)`."
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_neighbors = 3\n",
    "random_state = 0\n",
    "\n",
    "\n",
    "dim = len_labels\n",
    "n_classes = len_labels\n",
    "\n",
    "# Reduce dimension to 100 with PCA\n",
    "pca = make_pipeline(StandardScaler(),\n",
    "                    PCA(n_components=100, random_state=random_state))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_r = pca.fit(X).transform(y_train)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=2)\n",
    "X_r2 = lda.fit(X, y).transform(X)\n",
    "\n",
    "# Percentage of variance explained for each components\n",
    "print('explained variance ratio (first two components): %s'\n",
    "      % str(pca.explained_variance_ratio_))\n",
    "\n",
    "plt.figure()\n",
    "colors = ['navy', 'turquoise', 'darkorange']\n",
    "lw = 2\n",
    "\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r[y == i, 0], X_r[y == i, 1], color=color, alpha=.8, lw=lw,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('PCA of IRIS dataset')\n",
    "\n",
    "plt.figure()\n",
    "for color, i, target_name in zip(colors, [0, 1, 2], target_names):\n",
    "    plt.scatter(X_r2[y == i, 0], X_r2[y == i, 1], alpha=.8, color=color,\n",
    "                label=target_name)\n",
    "plt.legend(loc='best', shadow=False, scatterpoints=1)\n",
    "plt.title('LDA of IRIS dataset')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca_model.explained_varianceratio.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction des features à partir du path\n",
    "Différentes approches peuvent etre utilisées sur la colonne path:\n",
    "#### L'utilisation de TF-IDF \n",
    "- TF-IDF: refléte l'importance d'un mot pour un document dans une collection (corpus) mais ne prend pas en compte le sens sémantique des mots. TF signifie la probabilité d'occurrence d'un mot dans une phrase.\n",
    "- TF-IDF donne plus d'importance aux mots qui apparaissent moins fréquemment dans l'ensemble du corpus et donne également de l'importance aux mots les plus fréquents qui apparaissent dans chaque donnée.\n",
    "\n",
    "Nous testerons les featurizations suivantes:\n",
    "- TF-IDF: unigrams, bigrams, trigrams et word n-grams.\n",
    "- TF-IDF based character: unigrams, bigrams, trigrams. (considérer une séquence de caractères plutôt qu'une séquence de mots)\n",
    "\n",
    "\n",
    "#### L'utilisation des Embeddings (word2vec)\n",
    "- Word2vec est l'un des modèle de l'état de l'art pour les embeddings.  Il permet de convertir du texte en vecteurs numériques tout en préservantles relations sémantiques entre les mots.\n",
    "- vecteur de 300 dimensions \n",
    "\n",
    "#### L'utilisation d'une combinaison de TF-IDF et moyenne des Embeddings:\n",
    "Nombiner les n-grammes de caractères avec les vecteurs obtenus avec Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création des modèles :\n",
    "#### Baseslines: \n",
    "- Dans un premier temps, nous allons construire nos modèles Baselines avec l'ensemble des targets présentes dans notre dataset. Chaque modèle essaiera de prédire les targets sur le nombre total de 1009 targets. \n",
    "- Après avoir construit les baslines models, nous essaierons d'améliorer les modèles avec des hyperparamètres pour voir s'il y a une augmentation du score F1.\n",
    "\n",
    "#### Aller plus loin\n",
    "- Ensuite, nous construirons nos modèles en séléctionnant peu de colonnes par exemple.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression, Linear SVMs, SGD Classifiers avec log loss,\n",
    "SGD Classifier avec hinge loss\n",
    "objectif : maximiser le micro averaged F1 score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-label classification\n",
    "#### 1.  OneVsRest: \n",
    "Le problème est décomposé en un problème de classification binaire multiple. Nous choisissons une classe et formons un classificateur binaire avec les échantillons de la classe sélectionnée d'un côté et tous les autres échantillons de l'autre côté. Ainsi, nous obtiendrons N classificateurs pour N étiquettes et lors du test nous classerons simplement l'échantillon comme appartenant à la classe avec le score maximum parmi les N classificateurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-52512cc960ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOneVsRestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'l1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_multilabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_multilabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_multilabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\multiclass.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;31m# n_jobs > 1 in can results in slower performance due to the overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# of spawning threads.  See joblib issue #112.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         self.estimators_ = Parallel(n_jobs=self.n_jobs)(delayed(_fit_binary)(\n\u001b[0m\u001b[0;32m    242\u001b[0m             self.estimator, X, column, classes=[\n\u001b[0;32m    243\u001b[0m                 \u001b[1;34m\"not %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_binarizer_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1054\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1055\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    931\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 933\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    934\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier1 = OneVsRestClassifier(LogisticRegression(penalty='l1', solver='liblinear', class_weight=\"balanced\"), n_jobs=-1)\n",
    "classifier1.fit(X_train_multilabel, y_train_multilabel)\n",
    "predictions = classifier1.predict(X_test_multilabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.007278537191549796\n",
      "Hamming loss  0.0068070643314176215\n",
      "\n",
      "Micro-average quality numbers\n",
      "Precision: 0.2285, Recall: 0.7251, F1-measure: 0.3475\n",
      "\n",
      "Macro-average quality numbers\n",
      "Precision: 0.1337, Recall: 0.3929, F1-measure: 0.1884\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.35      0.08        23\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.10      0.20      0.13         5\n",
      "           4       0.20      0.70      0.31        43\n",
      "           5       0.09      0.33      0.14        18\n",
      "           6       0.00      0.00      0.00         0\n",
      "           7       0.07      0.23      0.10        22\n",
      "           8       0.06      0.15      0.09        13\n",
      "           9       0.03      0.25      0.06         4\n",
      "          10       0.33      0.20      0.25         5\n",
      "          11       0.12      0.54      0.19        52\n",
      "          12       0.13      0.36      0.19        22\n",
      "          13       0.21      0.56      0.31        50\n",
      "          14       0.00      0.00      0.00         8\n",
      "          15       0.13      0.48      0.21        33\n",
      "          16       0.06      0.25      0.10        52\n",
      "          17       0.09      0.69      0.16        13\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.17      0.67      0.27         3\n",
      "          20       0.13      0.54      0.21        37\n",
      "          21       0.26      0.72      0.38        83\n",
      "          22       0.00      0.00      0.00         5\n",
      "          23       0.24      0.75      0.36       220\n",
      "          24       0.00      0.00      0.00         5\n",
      "          25       0.12      0.35      0.18        17\n",
      "          26       0.09      0.71      0.15         7\n",
      "          27       0.12      0.50      0.20        10\n",
      "          28       0.02      0.20      0.03         5\n",
      "          29       0.21      0.58      0.31        26\n",
      "          30       0.16      0.62      0.26        13\n",
      "          31       0.12      0.60      0.20        52\n",
      "          32       0.00      0.00      0.00        11\n",
      "          33       0.03      0.17      0.05        12\n",
      "          34       0.25      0.65      0.36        40\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.05      0.29      0.09        17\n",
      "          37       0.05      0.44      0.08         9\n",
      "          38       0.08      0.41      0.13        37\n",
      "          39       0.13      0.41      0.20        27\n",
      "          40       0.08      0.39      0.13        41\n",
      "          41       0.47      0.89      0.62        81\n",
      "          42       0.03      0.12      0.04         8\n",
      "          43       0.04      0.27      0.08        11\n",
      "          44       0.22      0.76      0.34        94\n",
      "          45       0.16      0.63      0.26       100\n",
      "          46       0.15      0.66      0.25        32\n",
      "          47       0.21      0.68      0.32        76\n",
      "          48       0.09      0.51      0.15        82\n",
      "          49       0.19      0.63      0.29       186\n",
      "          50       0.18      0.72      0.28       144\n",
      "          51       0.26      0.68      0.37       177\n",
      "          52       0.11      0.58      0.19        36\n",
      "          53       0.00      0.00      0.00         5\n",
      "          54       0.04      0.25      0.06        12\n",
      "          55       0.22      0.90      0.35       153\n",
      "          56       0.19      0.66      0.30        77\n",
      "          57       0.25      1.00      0.40         1\n",
      "          58       0.00      0.00      0.00         0\n",
      "          59       0.25      0.67      0.36         9\n",
      "          60       0.00      0.00      0.00         2\n",
      "          61       0.29      1.00      0.45         5\n",
      "          62       0.62      0.89      0.73         9\n",
      "          63       0.44      0.73      0.55        11\n",
      "          64       1.00      0.67      0.80         3\n",
      "          65       0.28      0.80      0.41        10\n",
      "          66       0.50      0.50      0.50         2\n",
      "          67       0.33      0.76      0.46        89\n",
      "          68       0.18      0.67      0.28        12\n",
      "          69       0.52      0.84      0.64       303\n",
      "          70       0.03      0.30      0.06        33\n",
      "          71       0.33      0.73      0.46        15\n",
      "          72       0.10      0.46      0.17        52\n",
      "          73       0.13      0.50      0.21        18\n",
      "          74       0.10      0.40      0.16        10\n",
      "          75       0.51      0.76      0.61       437\n",
      "          76       0.05      0.31      0.09        32\n",
      "          77       0.37      0.83      0.51        18\n",
      "          78       0.47      0.93      0.62       551\n",
      "          79       0.28      0.84      0.42       129\n",
      "          80       0.00      0.00      0.00         6\n",
      "          81       0.03      0.15      0.05        13\n",
      "          82       0.30      0.75      0.43         4\n",
      "          83       0.07      0.35      0.12        54\n",
      "          84       0.22      0.75      0.35        65\n",
      "          85       0.24      0.64      0.35        53\n",
      "          86       0.10      0.61      0.17        18\n",
      "          87       0.05      0.18      0.07        11\n",
      "          88       0.08      0.40      0.13        10\n",
      "          89       0.11      0.27      0.16        11\n",
      "          90       0.00      0.00      0.00         3\n",
      "          91       0.00      0.00      0.00         2\n",
      "          92       0.14      0.65      0.23        94\n",
      "          93       0.35      0.81      0.49       365\n",
      "          94       0.29      0.77      0.42       308\n",
      "          95       0.27      0.82      0.41       188\n",
      "          96       0.19      0.76      0.30       174\n",
      "          97       0.02      0.17      0.04        12\n",
      "          98       0.02      0.25      0.04        16\n",
      "          99       0.21      0.67      0.32        15\n",
      "         100       0.05      0.59      0.10        41\n",
      "         101       0.04      0.40      0.07        10\n",
      "         102       0.03      0.29      0.06        21\n",
      "         103       0.10      0.66      0.17        53\n",
      "         104       0.04      0.47      0.08        43\n",
      "         105       0.02      0.23      0.04        13\n",
      "         106       0.28      0.83      0.42       172\n",
      "         107       0.55      0.89      0.68       403\n",
      "         108       0.07      0.33      0.11        27\n",
      "         109       0.05      0.47      0.09        59\n",
      "         110       0.09      0.45      0.15        71\n",
      "         111       0.25      0.84      0.39       182\n",
      "         112       0.13      0.68      0.21        79\n",
      "         113       0.11      0.50      0.18        14\n",
      "         114       0.00      0.00      0.00         2\n",
      "         115       0.02      0.12      0.04         8\n",
      "         116       0.07      0.50      0.13        66\n",
      "         117       0.05      0.39      0.09        41\n",
      "         118       0.00      0.00      0.00         4\n",
      "         119       0.83      0.96      0.89       514\n",
      "         120       0.07      0.26      0.11        19\n",
      "         121       0.06      0.33      0.10        15\n",
      "         122       0.05      0.30      0.08        23\n",
      "         123       0.06      0.56      0.11         9\n",
      "         124       0.05      0.29      0.08         7\n",
      "         125       0.00      0.00      0.00         0\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         4\n",
      "         128       0.02      0.06      0.03        16\n",
      "         129       0.03      0.30      0.05        10\n",
      "         130       0.05      0.34      0.09        29\n",
      "         131       0.06      0.29      0.10        41\n",
      "         132       0.09      0.47      0.15        59\n",
      "         133       0.12      0.50      0.20        50\n",
      "         134       0.18      0.64      0.29       131\n",
      "         135       0.26      0.83      0.40       149\n",
      "         136       0.18      0.50      0.27        40\n",
      "         137       0.20      0.68      0.31        37\n",
      "         138       0.12      0.63      0.20        43\n",
      "         139       0.23      0.80      0.35        60\n",
      "         140       0.18      0.33      0.24         6\n",
      "         141       0.32      0.91      0.48       128\n",
      "         142       0.39      0.99      0.56       238\n",
      "         143       0.13      0.65      0.22        60\n",
      "         144       0.19      0.89      0.31        64\n",
      "         145       0.27      0.91      0.41       226\n",
      "         146       0.07      0.50      0.13        12\n",
      "         147       0.07      0.42      0.12        12\n",
      "         148       0.00      0.00      0.00         0\n",
      "         149       0.33      0.77      0.46       148\n",
      "         150       0.14      0.40      0.20        15\n",
      "         151       0.09      0.47      0.15        15\n",
      "         152       0.12      0.41      0.19        22\n",
      "         153       0.10      0.44      0.17        68\n",
      "         154       0.24      0.67      0.35        49\n",
      "         155       0.31      0.82      0.45        67\n",
      "         156       0.13      0.50      0.21        32\n",
      "         157       0.10      0.27      0.15        11\n",
      "         158       0.09      0.32      0.14        22\n",
      "         159       0.32      0.79      0.46       104\n",
      "         160       0.33      0.82      0.47       157\n",
      "         161       0.09      0.45      0.15        38\n",
      "         162       0.03      0.10      0.05        10\n",
      "         163       0.06      0.15      0.09        13\n",
      "         164       0.10      0.46      0.16        50\n",
      "         165       0.02      0.07      0.04        14\n",
      "         166       0.00      0.00      0.00         5\n",
      "         167       0.28      0.82      0.42        45\n",
      "         168       0.46      0.87      0.60       255\n",
      "         169       0.49      0.71      0.58        65\n",
      "         170       0.12      0.59      0.20        39\n",
      "         171       0.08      0.51      0.14        49\n",
      "         172       0.12      0.40      0.19         5\n",
      "         173       0.03      0.41      0.05        32\n",
      "         174       0.09      0.52      0.15        33\n",
      "         175       0.30      0.87      0.44       267\n",
      "         176       0.00      0.00      0.00         1\n",
      "         177       0.02      0.10      0.03        10\n",
      "         178       0.00      0.00      0.00         5\n",
      "         179       0.10      0.57      0.17         7\n",
      "         180       0.07      0.48      0.12        48\n",
      "         181       0.05      0.43      0.09        47\n",
      "         182       0.00      0.00      0.00         5\n",
      "         183       0.25      0.71      0.37        70\n",
      "         184       0.42      0.88      0.57       444\n",
      "         185       0.16      0.57      0.25        40\n",
      "         186       0.32      0.61      0.42        41\n",
      "         187       0.08      0.38      0.13        48\n",
      "         188       0.04      0.33      0.07         9\n",
      "         189       0.20      0.56      0.30        50\n",
      "         190       0.36      0.87      0.50       181\n",
      "         191       0.36      0.88      0.51       320\n",
      "         192       0.18      0.72      0.29        87\n",
      "         193       0.02      0.17      0.04        18\n",
      "         194       0.52      0.81      0.63       305\n",
      "         195       0.02      0.19      0.04        26\n",
      "         196       0.06      0.44      0.10        34\n",
      "         197       0.11      0.46      0.18        50\n",
      "         198       0.11      0.65      0.19        40\n",
      "         199       0.04      0.12      0.06        25\n",
      "         200       0.35      0.66      0.46        47\n",
      "         201       0.04      0.50      0.07         2\n",
      "         202       0.05      0.17      0.07        18\n",
      "         203       0.08      0.20      0.11        15\n",
      "         204       0.00      0.00      0.00         2\n",
      "         205       0.14      0.58      0.22        38\n",
      "         206       0.04      0.30      0.07        23\n",
      "         207       0.23      0.85      0.36        26\n",
      "         208       0.07      0.45      0.12        22\n",
      "         209       0.28      0.78      0.41        85\n",
      "         210       0.50      0.63      0.56        27\n",
      "         211       0.15      0.65      0.24        46\n",
      "         212       0.12      0.64      0.20        25\n",
      "         213       0.10      0.58      0.17        31\n",
      "         214       0.27      0.69      0.39        88\n",
      "         215       0.26      0.70      0.38        57\n",
      "         216       0.15      0.31      0.20        16\n",
      "         217       0.57      0.92      0.70       749\n",
      "         218       0.20      0.59      0.30        59\n",
      "         219       0.00      0.00      0.00         4\n",
      "         220       0.18      0.66      0.29       263\n",
      "         221       0.16      0.62      0.26        13\n",
      "         222       0.39      0.90      0.55        10\n",
      "         223       0.00      0.00      0.00         2\n",
      "         224       0.02      0.24      0.04        17\n",
      "         225       0.03      0.30      0.05        10\n",
      "         226       0.11      0.42      0.17        24\n",
      "         227       0.10      0.20      0.13         5\n",
      "         228       0.13      0.57      0.21        90\n",
      "         229       0.42      0.88      0.57        56\n",
      "         230       0.21      0.58      0.30        33\n",
      "         231       0.18      0.58      0.27        53\n",
      "         232       0.48      0.97      0.64       345\n",
      "         233       0.00      0.00      0.00         0\n",
      "         234       0.00      0.00      0.00         1\n",
      "         235       0.40      0.50      0.44         4\n",
      "         236       0.10      0.12      0.11        16\n",
      "         237       0.34      0.92      0.49        63\n",
      "         238       0.09      0.53      0.15        53\n",
      "         239       0.47      0.72      0.57        25\n",
      "         240       0.23      0.70      0.35        23\n",
      "         241       0.05      0.50      0.09         2\n",
      "         242       0.06      0.29      0.10        14\n",
      "         243       0.15      0.47      0.23        83\n",
      "         244       0.03      0.14      0.05         7\n",
      "         245       0.57      0.70      0.63        23\n",
      "         246       0.06      0.18      0.09        11\n",
      "         247       0.00      0.00      0.00         5\n",
      "         248       0.68      0.87      0.76        46\n",
      "         249       0.00      0.00      0.00         6\n",
      "         250       0.00      0.00      0.00         1\n",
      "         251       0.00      0.00      0.00         3\n",
      "         252       0.33      0.86      0.47       112\n",
      "         253       0.92      0.97      0.95       578\n",
      "         254       0.07      0.20      0.11         5\n",
      "         255       0.22      0.40      0.29         5\n",
      "         256       0.00      0.00      0.00         1\n",
      "         257       0.10      0.46      0.17        56\n",
      "         258       0.19      0.70      0.30       163\n",
      "         259       0.26      0.77      0.39        88\n",
      "         260       0.07      0.22      0.11        23\n",
      "         261       0.04      0.29      0.07         7\n",
      "         262       0.67      1.00      0.80         4\n",
      "         263       0.17      0.87      0.28       140\n",
      "         264       0.78      0.99      0.87       910\n",
      "         265       0.20      0.88      0.33       144\n",
      "         266       0.16      0.68      0.26        77\n",
      "         267       0.00      0.00      0.00         3\n",
      "         268       0.04      0.50      0.08         4\n",
      "         269       0.09      0.43      0.15        23\n",
      "         270       0.17      0.33      0.22         3\n",
      "         271       0.10      0.58      0.17        55\n",
      "         272       0.24      0.68      0.36        99\n",
      "         273       0.04      0.25      0.07         8\n",
      "         274       0.09      0.33      0.14         6\n",
      "         275       0.05      0.08      0.06        13\n",
      "         276       0.39      0.87      0.54       229\n",
      "         277       0.02      0.22      0.04         9\n",
      "         278       0.00      0.00      0.00         0\n",
      "         279       0.06      0.17      0.09        12\n",
      "         280       0.04      0.25      0.07         4\n",
      "         281       0.00      0.00      0.00         4\n",
      "         282       0.18      0.52      0.26        29\n",
      "         283       0.00      0.00      0.00         2\n",
      "         284       0.00      0.00      0.00         2\n",
      "         285       0.00      0.00      0.00         2\n",
      "         286       0.00      0.00      0.00         0\n",
      "         287       0.05      0.28      0.08        39\n",
      "         288       0.00      0.00      0.00         1\n",
      "         289       0.18      0.58      0.27        48\n",
      "         290       0.04      0.43      0.07        46\n",
      "         291       0.25      0.74      0.38       125\n",
      "         292       0.19      0.57      0.28        49\n",
      "         293       0.07      0.31      0.12        13\n",
      "         294       0.03      0.17      0.05         6\n",
      "         295       0.00      0.00      0.00         1\n",
      "         296       0.25      0.20      0.22         5\n",
      "         297       0.01      0.20      0.03         5\n",
      "         298       0.00      0.00      0.00         3\n",
      "         299       0.04      0.67      0.08         3\n",
      "         300       0.05      0.33      0.09         3\n",
      "         301       0.05      0.40      0.09        10\n",
      "         302       0.00      0.00      0.00         2\n",
      "         303       0.13      0.67      0.22         3\n",
      "         304       0.06      0.14      0.08         7\n",
      "         305       0.08      0.20      0.11         5\n",
      "         306       0.05      0.31      0.08        13\n",
      "         307       0.00      0.00      0.00         0\n",
      "         308       0.09      0.63      0.16        92\n",
      "         309       0.47      0.94      0.63       470\n",
      "         310       0.04      0.50      0.07         2\n",
      "         311       0.12      0.50      0.19         6\n",
      "         312       0.00      0.00      0.00         1\n",
      "         313       0.00      0.00      0.00         2\n",
      "         314       0.00      0.00      0.00         3\n",
      "         315       0.19      0.75      0.31        67\n",
      "         316       0.36      0.71      0.48        28\n",
      "         317       0.30      0.53      0.38        15\n",
      "         318       0.52      0.75      0.61        36\n",
      "         319       0.15      0.62      0.24         8\n",
      "         320       0.10      0.42      0.17        12\n",
      "         321       0.06      0.33      0.10         3\n",
      "         322       0.17      0.33      0.22         3\n",
      "         323       0.11      0.53      0.18        15\n",
      "         324       0.09      0.50      0.15        10\n",
      "         325       0.06      0.33      0.10         3\n",
      "         326       0.03      0.27      0.05        15\n",
      "         327       0.17      0.67      0.27         3\n",
      "         328       0.06      0.50      0.11         2\n",
      "         329       0.17      0.82      0.29        22\n",
      "         330       0.10      0.79      0.17        14\n",
      "         331       0.17      0.71      0.27        24\n",
      "         332       0.31      0.75      0.44        16\n",
      "         333       0.00      0.00      0.00         1\n",
      "         334       0.05      0.42      0.09        31\n",
      "         335       0.20      0.60      0.30         5\n",
      "         336       0.13      0.61      0.22        18\n",
      "         337       0.46      0.90      0.61       485\n",
      "         338       0.28      0.64      0.39        11\n",
      "         339       0.29      0.50      0.37        18\n",
      "         340       0.33      0.78      0.47         9\n",
      "         341       0.00      0.00      0.00         1\n",
      "         342       0.30      0.84      0.44       154\n",
      "         343       0.05      0.24      0.08        17\n",
      "         344       0.14      0.20      0.17         5\n",
      "         345       0.50      1.00      0.67         1\n",
      "         346       0.00      0.00      0.00         1\n",
      "         347       0.12      0.60      0.20         5\n",
      "         348       0.36      0.79      0.49        47\n",
      "         349       0.29      0.88      0.43        16\n",
      "         350       0.43      0.82      0.57        49\n",
      "         351       0.32      0.77      0.45        35\n",
      "         352       0.13      0.57      0.21         7\n",
      "         353       0.00      0.00      0.00         2\n",
      "         354       0.00      0.00      0.00         1\n",
      "         355       0.11      0.48      0.18        65\n",
      "         356       0.65      0.84      0.73        37\n",
      "         357       0.37      0.71      0.48        31\n",
      "         358       0.12      0.87      0.21        23\n",
      "         359       0.34      0.73      0.47        85\n",
      "         360       0.35      0.83      0.49       241\n",
      "         361       0.51      0.89      0.65       278\n",
      "         362       0.48      0.89      0.62       150\n",
      "         363       0.40      0.84      0.54       146\n",
      "         364       0.37      0.76      0.50       395\n",
      "         365       0.53      0.89      0.66       296\n",
      "         366       0.09      0.40      0.15        10\n",
      "         367       0.40      0.83      0.54       217\n",
      "         368       0.08      0.38      0.13        21\n",
      "         369       0.14      0.57      0.23        92\n",
      "         370       0.00      0.00      0.00         2\n",
      "         371       0.33      0.33      0.33         3\n",
      "         372       0.00      0.00      0.00         3\n",
      "         373       0.00      0.00      0.00         0\n",
      "         374       0.16      0.78      0.26        58\n",
      "         375       0.13      0.70      0.21        81\n",
      "         376       0.11      0.31      0.17        29\n",
      "         377       0.38      0.85      0.52        71\n",
      "         378       0.00      0.00      0.00         6\n",
      "         379       0.42      0.80      0.55        35\n",
      "         380       0.10      0.44      0.16         9\n",
      "         381       0.00      0.00      0.00         3\n",
      "         382       0.00      0.00      0.00         3\n",
      "         383       0.06      0.43      0.11        14\n",
      "         384       0.07      0.50      0.13        12\n",
      "         385       0.00      0.00      0.00         0\n",
      "         386       0.00      0.00      0.00         6\n",
      "         387       0.06      0.27      0.10        11\n",
      "         388       0.00      0.00      0.00         3\n",
      "         389       0.21      0.82      0.33        11\n",
      "         390       0.10      0.67      0.18         9\n",
      "         391       0.12      0.38      0.18         8\n",
      "         392       0.24      0.74      0.36        35\n",
      "         393       0.03      0.30      0.05        40\n",
      "         394       0.11      0.30      0.16        20\n",
      "         395       0.19      0.46      0.27        13\n",
      "         396       0.00      0.00      0.00         7\n",
      "         397       0.16      0.70      0.26        10\n",
      "         398       0.20      0.62      0.30        16\n",
      "         399       0.00      0.00      0.00         0\n",
      "         400       0.00      0.00      0.00         1\n",
      "         401       0.14      0.44      0.21         9\n",
      "         402       0.27      0.38      0.32         8\n",
      "         403       0.09      0.21      0.13        14\n",
      "         404       0.22      0.22      0.22         9\n",
      "         405       0.07      0.60      0.12        10\n",
      "         406       0.11      0.66      0.19        68\n",
      "         407       0.20      0.73      0.32       123\n",
      "         408       0.08      0.37      0.14        67\n",
      "         409       0.05      0.38      0.08        24\n",
      "         410       0.33      0.67      0.44         9\n",
      "         411       0.50      0.83      0.62         6\n",
      "         412       0.17      0.50      0.26        12\n",
      "         413       0.10      0.33      0.15        18\n",
      "         414       0.09      0.33      0.14        24\n",
      "         415       0.09      0.30      0.14        23\n",
      "         416       0.03      0.11      0.05         9\n",
      "         417       0.04      0.20      0.07         5\n",
      "         418       0.12      0.50      0.20         8\n",
      "         419       0.07      0.20      0.10         5\n",
      "         420       0.00      0.00      0.00         4\n",
      "         421       0.00      0.00      0.00         5\n",
      "         422       0.28      0.79      0.41        34\n",
      "         423       0.00      0.00      0.00         2\n",
      "         424       0.00      0.00      0.00         1\n",
      "         425       0.12      0.46      0.19        13\n",
      "         426       0.67      0.67      0.67         3\n",
      "         427       0.13      0.46      0.20        28\n",
      "         428       0.36      0.40      0.38        10\n",
      "         429       0.18      0.42      0.25        12\n",
      "         430       0.11      0.50      0.18         6\n",
      "         431       0.00      0.00      0.00         1\n",
      "         432       0.08      0.60      0.14         5\n",
      "         433       0.33      0.62      0.43         8\n",
      "         434       0.10      0.40      0.16         5\n",
      "         435       0.00      0.00      0.00         1\n",
      "         436       0.12      0.58      0.20        12\n",
      "         437       0.07      0.25      0.11         8\n",
      "         438       0.40      0.45      0.43        22\n",
      "         439       0.04      0.14      0.06         7\n",
      "         440       0.00      0.00      0.00         1\n",
      "         441       0.44      0.64      0.52        11\n",
      "         442       0.45      0.38      0.42        13\n",
      "         443       0.09      0.20      0.13         5\n",
      "         444       0.00      0.00      0.00         4\n",
      "         445       0.00      0.00      0.00         0\n",
      "         446       0.10      0.50      0.17         2\n",
      "         447       0.00      0.00      0.00         2\n",
      "         448       0.24      0.81      0.37        52\n",
      "         449       0.00      0.00      0.00         8\n",
      "         450       0.18      0.64      0.29        11\n",
      "         451       0.10      0.44      0.16         9\n",
      "         452       0.23      0.77      0.35        31\n",
      "         453       0.08      0.25      0.12         4\n",
      "         454       0.29      0.71      0.42        14\n",
      "         455       0.03      0.10      0.05        10\n",
      "         456       0.00      0.00      0.00         2\n",
      "         457       0.41      0.88      0.56        84\n",
      "         458       0.11      0.50      0.18         2\n",
      "         459       0.35      0.85      0.50        73\n",
      "         460       0.22      0.75      0.34        85\n",
      "         461       0.00      0.00      0.00         1\n",
      "         462       0.08      0.33      0.13        18\n",
      "         463       0.00      0.00      0.00         2\n",
      "         464       0.00      0.00      0.00         0\n",
      "         465       0.05      0.17      0.08         6\n",
      "         466       0.07      0.67      0.12         3\n",
      "         467       0.16      0.62      0.25        29\n",
      "         468       0.24      0.66      0.35        44\n",
      "         469       0.05      0.40      0.09         5\n",
      "         470       0.05      0.33      0.09         6\n",
      "         471       0.26      0.77      0.39        78\n",
      "         472       0.08      0.38      0.13        16\n",
      "         473       0.00      0.00      0.00        10\n",
      "         474       0.00      0.00      0.00         4\n",
      "         475       0.00      0.00      0.00         1\n",
      "         476       0.00      0.00      0.00         4\n",
      "         477       0.06      0.36      0.10        11\n",
      "         478       0.20      0.53      0.29        15\n",
      "         479       0.00      0.00      0.00         3\n",
      "         480       0.00      0.00      0.00         0\n",
      "         481       0.00      0.00      0.00         1\n",
      "         482       0.11      0.55      0.19        29\n",
      "         483       0.11      0.33      0.17         3\n",
      "         484       0.10      0.33      0.15         9\n",
      "         485       0.04      0.44      0.07         9\n",
      "         486       0.00      0.00      0.00         2\n",
      "         487       0.00      0.00      0.00         3\n",
      "         488       0.04      0.12      0.06        24\n",
      "         489       0.45      0.91      0.61        11\n",
      "         490       0.35      1.00      0.52        11\n",
      "         491       0.30      0.79      0.44        84\n",
      "         492       0.24      0.85      0.37        54\n",
      "         493       0.33      0.80      0.46        86\n",
      "         494       0.05      0.17      0.08         6\n",
      "         495       0.01      0.10      0.03        20\n",
      "         496       0.14      0.81      0.24        70\n",
      "         497       0.71      0.99      0.83       845\n",
      "         498       0.06      0.24      0.09        21\n",
      "         499       0.11      0.50      0.18        10\n",
      "         500       0.03      0.25      0.06         4\n",
      "         501       0.07      0.25      0.11         4\n",
      "         502       0.08      0.22      0.12         9\n",
      "         503       0.16      0.27      0.20        11\n",
      "         504       0.16      0.54      0.25        35\n",
      "         505       0.27      0.64      0.38        11\n",
      "         506       0.22      0.57      0.32         7\n",
      "         507       0.08      0.43      0.14         7\n",
      "         508       0.08      0.27      0.13        11\n",
      "         509       0.08      0.45      0.14        11\n",
      "         510       0.00      0.00      0.00         2\n",
      "         511       0.10      0.83      0.19         6\n",
      "         512       0.04      0.25      0.07         4\n",
      "         513       0.15      0.33      0.21        12\n",
      "         514       0.09      0.56      0.15         9\n",
      "         515       0.05      0.29      0.08        28\n",
      "         516       0.40      0.85      0.54       324\n",
      "         517       0.12      0.67      0.20        45\n",
      "         518       0.18      0.73      0.29       169\n",
      "         519       0.04      0.25      0.07        20\n",
      "         520       0.03      0.15      0.05        27\n",
      "         521       0.08      0.39      0.14        36\n",
      "         522       0.07      0.20      0.10        15\n",
      "         523       0.00      0.00      0.00         1\n",
      "         524       0.11      0.33      0.17         3\n",
      "         525       0.05      1.00      0.10         1\n",
      "         526       0.05      0.23      0.08        22\n",
      "         527       0.00      0.00      0.00         4\n",
      "         528       0.15      0.68      0.25        31\n",
      "         529       0.48      0.86      0.61       474\n",
      "         530       0.19      0.66      0.30        29\n",
      "         531       0.00      0.00      0.00         9\n",
      "         532       0.17      0.75      0.28        95\n",
      "         533       0.45      0.86      0.59        22\n",
      "         534       0.04      0.29      0.08        14\n",
      "         535       0.08      0.50      0.14        36\n",
      "         536       0.51      0.89      0.65       229\n",
      "         537       0.33      0.81      0.47       150\n",
      "         538       0.00      0.00      0.00         1\n",
      "         539       0.00      0.00      0.00         1\n",
      "         540       0.18      0.61      0.27       136\n",
      "         541       0.00      0.00      0.00         3\n",
      "         542       0.21      0.68      0.32        50\n",
      "         543       0.09      0.43      0.15         7\n",
      "         544       0.18      0.74      0.28       121\n",
      "         545       0.26      0.82      0.40        73\n",
      "         546       0.26      0.76      0.39       140\n",
      "         547       0.24      0.69      0.36       135\n",
      "         548       0.37      0.86      0.52       322\n",
      "         549       0.18      0.50      0.26         6\n",
      "         550       0.00      0.00      0.00         5\n",
      "         551       0.28      0.88      0.43       110\n",
      "         552       0.11      0.50      0.18         4\n",
      "         553       0.16      0.66      0.26        38\n",
      "         554       0.09      0.21      0.12        14\n",
      "         555       0.17      0.89      0.29         9\n",
      "         556       0.25      1.00      0.40         1\n",
      "         557       0.02      0.17      0.04         6\n",
      "         558       0.17      0.66      0.26       144\n",
      "         559       0.31      0.73      0.43        52\n",
      "         560       0.19      0.60      0.29         5\n",
      "         561       0.07      0.32      0.12        19\n",
      "         562       0.00      0.00      0.00         2\n",
      "         563       0.12      0.25      0.17         8\n",
      "         564       0.07      0.33      0.11         3\n",
      "         565       0.02      0.33      0.04         3\n",
      "         566       0.00      0.00      0.00         2\n",
      "         567       0.00      0.00      0.00         3\n",
      "         568       0.00      0.00      0.00         5\n",
      "         569       0.11      0.33      0.17         3\n",
      "         570       0.00      0.00      0.00         1\n",
      "         571       0.00      0.00      0.00         3\n",
      "         572       0.27      0.77      0.40        44\n",
      "         573       0.31      0.64      0.42        44\n",
      "         574       0.10      0.25      0.14         8\n",
      "         575       0.41      0.85      0.56       391\n",
      "         576       0.10      0.50      0.17         4\n",
      "         577       0.00      0.00      0.00         0\n",
      "         578       0.07      0.28      0.11        25\n",
      "         579       0.08      0.25      0.12         4\n",
      "         580       0.04      0.43      0.07         7\n",
      "         581       0.18      0.47      0.26        15\n",
      "         582       0.09      0.47      0.15        75\n",
      "         583       0.17      0.60      0.26        62\n",
      "         584       0.17      0.58      0.26        36\n",
      "         585       0.18      0.69      0.28        29\n",
      "         586       0.18      0.45      0.26        22\n",
      "         587       0.17      0.70      0.28        53\n",
      "         588       0.20      0.59      0.30        96\n",
      "         589       0.19      0.64      0.29        72\n",
      "         590       0.18      0.70      0.29        53\n",
      "         591       0.11      0.58      0.18        26\n",
      "         592       0.12      0.50      0.20         8\n",
      "         593       0.14      0.36      0.20        14\n",
      "         594       0.00      0.00      0.00         1\n",
      "         595       0.00      0.00      0.00         0\n",
      "         596       0.09      0.50      0.15         6\n",
      "         597       0.15      0.31      0.21        13\n",
      "         598       0.11      0.33      0.17         9\n",
      "         599       0.10      0.25      0.14         8\n",
      "         600       0.45      0.78      0.57        23\n",
      "         601       0.23      0.71      0.35        42\n",
      "         602       0.57      0.82      0.67       309\n",
      "         603       0.23      0.62      0.34       264\n",
      "         604       0.35      0.80      0.48        80\n",
      "         605       0.41      0.83      0.55        66\n",
      "         606       0.39      0.85      0.54       126\n",
      "         607       0.34      0.85      0.49        72\n",
      "         608       0.32      0.79      0.46        48\n",
      "         609       0.32      0.69      0.44        35\n",
      "         610       0.25      0.56      0.35        16\n",
      "         611       0.24      0.65      0.35        26\n",
      "         612       0.20      0.61      0.30        23\n",
      "         613       0.30      0.82      0.44        68\n",
      "         614       0.00      0.00      0.00         6\n",
      "         615       0.00      0.00      0.00         2\n",
      "         616       0.08      0.67      0.14         3\n",
      "         617       0.41      0.84      0.55        69\n",
      "         618       0.00      0.00      0.00         2\n",
      "         619       0.00      0.00      0.00         1\n",
      "         620       0.00      0.00      0.00         2\n",
      "         621       0.19      0.54      0.28        13\n",
      "         622       0.00      0.00      0.00         2\n",
      "         623       0.08      0.67      0.14         3\n",
      "         624       0.04      0.17      0.07         6\n",
      "         625       0.09      0.17      0.12         6\n",
      "         626       0.00      0.00      0.00         1\n",
      "         627       0.18      0.44      0.26         9\n",
      "         628       0.18      0.67      0.29         9\n",
      "         629       0.00      0.00      0.00         2\n",
      "         630       0.08      0.62      0.14         8\n",
      "         631       0.35      0.50      0.41        16\n",
      "         632       0.22      0.66      0.33        35\n",
      "         633       0.00      0.00      0.00         5\n",
      "         634       0.00      0.00      0.00         1\n",
      "         635       0.09      1.00      0.17         3\n",
      "         636       0.08      1.00      0.14         1\n",
      "         637       0.05      0.12      0.07         8\n",
      "         638       0.03      0.11      0.05         9\n",
      "         639       0.00      0.00      0.00         0\n",
      "         640       0.00      0.00      0.00         0\n",
      "         641       0.33      0.83      0.48         6\n",
      "         642       0.50      1.00      0.67         2\n",
      "         643       0.13      0.22      0.17         9\n",
      "         644       0.27      0.40      0.32        10\n",
      "         645       0.00      0.00      0.00         2\n",
      "         646       0.00      0.00      0.00         0\n",
      "         647       0.00      0.00      0.00         1\n",
      "         648       0.00      0.00      0.00         0\n",
      "         649       0.20      0.20      0.20         5\n",
      "         650       0.04      0.10      0.06        10\n",
      "         651       0.00      0.00      0.00         1\n",
      "         652       0.00      0.00      0.00         0\n",
      "         653       0.12      1.00      0.22         1\n",
      "         654       0.19      0.58      0.29        12\n",
      "         655       0.13      0.65      0.21        81\n",
      "         656       0.04      0.36      0.08        14\n",
      "         657       0.57      0.95      0.71       624\n",
      "         658       0.58      0.95      0.72       630\n",
      "         659       0.23      0.71      0.35        91\n",
      "         660       0.18      0.74      0.30        61\n",
      "         661       0.34      0.91      0.50       241\n",
      "         662       0.06      0.26      0.10        19\n",
      "         663       0.31      0.90      0.46       223\n",
      "         664       0.49      0.93      0.64       371\n",
      "         665       0.21      0.85      0.34       165\n",
      "         666       0.27      0.72      0.39       123\n",
      "         667       0.24      0.90      0.38       117\n",
      "         668       0.17      0.66      0.27        44\n",
      "         669       0.19      0.79      0.31       126\n",
      "         670       0.00      0.00      0.00         1\n",
      "         671       0.12      0.22      0.15         9\n",
      "         672       0.02      0.14      0.04         7\n",
      "         673       0.08      0.50      0.14         2\n",
      "         674       0.18      0.42      0.25        12\n",
      "         675       0.10      0.52      0.17        33\n",
      "         676       0.00      0.00      0.00         2\n",
      "         677       0.08      0.50      0.14        10\n",
      "         678       0.03      0.14      0.05         7\n",
      "         679       1.00      1.00      1.00         1\n",
      "         680       0.00      0.00      0.00         0\n",
      "         681       0.77      0.91      0.83       231\n",
      "         682       0.05      0.29      0.08        24\n",
      "         683       0.03      0.25      0.05         4\n",
      "         684       0.24      0.84      0.38        73\n",
      "         685       0.07      0.63      0.12        30\n",
      "         686       0.00      0.00      0.00         3\n",
      "         687       0.02      0.07      0.03        14\n",
      "         688       0.26      0.72      0.38        36\n",
      "         689       0.32      0.81      0.46       198\n",
      "         690       0.47      0.87      0.61       266\n",
      "         691       0.41      0.87      0.56       136\n",
      "         692       0.34      0.73      0.46        49\n",
      "         693       0.20      0.67      0.31        15\n",
      "         694       0.22      0.80      0.35        65\n",
      "         695       0.11      0.52      0.18        27\n",
      "         696       0.20      0.62      0.31        16\n",
      "         697       0.13      0.65      0.22        37\n",
      "         698       0.29      0.73      0.41        44\n",
      "         699       0.27      0.81      0.40       129\n",
      "         700       0.22      0.65      0.33        43\n",
      "         701       0.20      0.64      0.30        25\n",
      "         702       0.18      0.67      0.29        52\n",
      "         703       0.17      0.54      0.26        28\n",
      "         704       0.00      0.00      0.00         7\n",
      "         705       0.04      0.12      0.06        16\n",
      "         706       0.15      0.45      0.22        11\n",
      "         707       0.18      0.63      0.28        27\n",
      "         708       0.25      0.20      0.22         5\n",
      "         709       0.00      0.00      0.00         0\n",
      "         710       0.00      0.00      0.00         1\n",
      "         711       0.00      0.00      0.00         0\n",
      "         712       0.04      0.40      0.07         5\n",
      "         713       0.07      1.00      0.13         2\n",
      "         714       0.28      0.65      0.39        37\n",
      "         715       0.09      1.00      0.17         1\n",
      "         716       0.29      0.91      0.44        33\n",
      "         717       0.24      0.73      0.36        48\n",
      "         718       0.21      0.63      0.32        27\n",
      "         719       0.17      0.50      0.25         6\n",
      "         720       0.11      0.31      0.16        16\n",
      "         721       0.17      0.57      0.27         7\n",
      "         722       0.00      0.00      0.00         2\n",
      "         723       0.00      0.00      0.00         0\n",
      "         724       0.11      0.58      0.18        19\n",
      "         725       0.23      0.68      0.35        28\n",
      "         726       0.12      0.71      0.21        14\n",
      "         727       0.17      0.65      0.27        37\n",
      "         728       0.20      0.68      0.31        19\n",
      "         729       0.20      0.74      0.31        27\n",
      "         730       0.20      0.78      0.31        18\n",
      "         731       0.24      0.75      0.37        16\n",
      "         732       0.19      0.50      0.27        46\n",
      "         733       0.14      0.67      0.23        24\n",
      "         734       0.22      0.69      0.33        13\n",
      "         735       0.17      0.61      0.27        38\n",
      "         736       0.22      0.69      0.33        52\n",
      "         737       0.22      0.76      0.35        58\n",
      "         738       0.09      0.40      0.15        15\n",
      "         739       0.09      0.55      0.15        22\n",
      "         740       0.23      0.81      0.36       186\n",
      "         741       0.06      0.40      0.11         5\n",
      "         742       0.08      0.20      0.12         5\n",
      "         743       0.35      0.54      0.42        13\n",
      "         744       0.54      1.00      0.70        21\n",
      "         745       0.31      0.85      0.45        26\n",
      "         746       0.12      0.83      0.21         6\n",
      "         747       0.17      0.27      0.21        11\n",
      "         748       0.38      0.84      0.53        69\n",
      "         749       0.13      0.43      0.20        44\n",
      "         750       0.17      0.68      0.27        25\n",
      "         751       0.16      0.40      0.23        10\n",
      "         752       0.00      0.00      0.00         1\n",
      "         753       0.00      0.00      0.00         2\n",
      "         754       0.06      1.00      0.11         1\n",
      "         755       0.05      0.18      0.08        11\n",
      "         756       0.07      0.24      0.11        21\n",
      "         757       0.12      0.78      0.21        73\n",
      "         758       0.05      0.15      0.07        13\n",
      "         759       0.09      0.47      0.15        19\n",
      "         760       0.08      0.48      0.14        29\n",
      "         761       0.25      0.71      0.37        21\n",
      "         762       0.05      0.14      0.08         7\n",
      "         763       0.18      0.65      0.28        20\n",
      "         764       0.07      0.47      0.12        15\n",
      "         765       0.00      0.00      0.00         3\n",
      "         766       0.00      0.00      0.00         5\n",
      "         767       0.00      0.00      0.00         0\n",
      "         768       0.00      0.00      0.00         0\n",
      "         769       0.44      0.53      0.48        15\n",
      "         770       0.75      0.50      0.60         6\n",
      "         771       0.00      0.00      0.00         2\n",
      "         772       0.43      0.69      0.53        13\n",
      "         773       0.00      0.00      0.00         1\n",
      "         774       0.00      0.00      0.00         1\n",
      "         775       0.13      0.58      0.21       295\n",
      "         776       0.00      0.00      0.00         1\n",
      "         777       0.08      0.48      0.13        23\n",
      "         778       0.12      0.34      0.18        44\n",
      "         779       0.00      0.00      0.00         1\n",
      "         780       0.25      0.78      0.37        40\n",
      "         781       0.08      0.51      0.14        37\n",
      "         782       0.23      0.56      0.32        18\n",
      "         783       0.25      0.73      0.37        30\n",
      "         784       0.00      0.00      0.00         0\n",
      "         785       0.00      0.00      0.00         5\n",
      "         786       0.00      0.00      0.00         2\n",
      "         787       0.44      0.82      0.57       861\n",
      "         788       0.00      0.00      0.00         0\n",
      "         789       0.06      0.46      0.11        24\n",
      "         790       0.20      0.61      0.31        18\n",
      "         791       0.20      0.62      0.30       145\n",
      "         792       0.20      0.50      0.29         2\n",
      "         793       0.28      0.72      0.40        76\n",
      "         794       0.01      0.11      0.03         9\n",
      "         795       0.45      0.93      0.60        14\n",
      "         796       0.33      0.57      0.42         7\n",
      "         797       0.00      0.00      0.00         1\n",
      "         798       0.31      0.57      0.40         7\n",
      "         799       0.20      0.69      0.31        16\n",
      "         800       0.45      0.88      0.60       117\n",
      "         801       0.22      0.80      0.34        44\n",
      "         802       0.21      0.71      0.33        63\n",
      "         803       0.09      0.45      0.15        33\n",
      "         804       0.17      0.65      0.27        52\n",
      "         805       0.32      0.66      0.43        41\n",
      "         806       0.11      0.50      0.18         2\n",
      "         807       0.23      0.76      0.35        45\n",
      "         808       0.19      0.80      0.31        49\n",
      "         809       0.00      0.00      0.00         0\n",
      "         810       0.00      0.00      0.00         1\n",
      "         811       0.50      1.00      0.67         1\n",
      "         812       0.02      0.07      0.03        14\n",
      "         813       0.50      1.00      0.67         1\n",
      "         814       0.12      0.50      0.20         2\n",
      "         815       0.00      0.00      0.00         2\n",
      "         816       0.00      0.00      0.00         0\n",
      "         817       0.00      0.00      0.00         0\n",
      "         818       0.02      0.18      0.04        11\n",
      "         819       0.00      0.00      0.00         2\n",
      "         820       0.21      0.65      0.32       242\n",
      "         821       0.03      0.12      0.04         8\n",
      "         822       0.31      0.86      0.45        81\n",
      "         823       0.33      0.69      0.45        39\n",
      "         824       0.00      0.00      0.00         0\n",
      "         825       0.14      0.27      0.18        22\n",
      "         826       0.03      0.18      0.06        11\n",
      "         827       0.39      0.82      0.53        55\n",
      "         828       0.11      0.35      0.16        23\n",
      "         829       0.66      0.97      0.79       452\n",
      "         830       0.26      0.72      0.39       541\n",
      "         831       0.09      0.33      0.14        24\n",
      "         832       0.33      0.82      0.47        88\n",
      "         833       0.14      0.43      0.21        14\n",
      "         834       0.16      0.88      0.27       105\n",
      "         835       0.03      0.30      0.06        10\n",
      "         836       0.27      0.76      0.40       390\n",
      "         837       0.16      0.73      0.26        81\n",
      "         838       0.21      0.63      0.31        35\n",
      "         839       0.24      0.72      0.36        18\n",
      "         840       0.35      0.67      0.46        36\n",
      "         841       0.07      0.33      0.12         9\n",
      "         842       0.29      0.61      0.39        18\n",
      "         843       0.13      0.55      0.21        40\n",
      "         844       0.03      0.23      0.06        13\n",
      "         845       0.23      0.70      0.35        37\n",
      "         846       0.02      0.25      0.03         8\n",
      "         847       0.03      0.08      0.04        12\n",
      "         848       0.19      0.73      0.30        74\n",
      "         849       0.24      0.56      0.34        16\n",
      "         850       0.19      0.57      0.28       127\n",
      "         851       0.07      0.31      0.12        45\n",
      "         852       0.14      0.33      0.19        18\n",
      "         853       0.22      0.73      0.34        11\n",
      "         854       0.04      0.46      0.07        41\n",
      "         855       0.12      0.38      0.18        16\n",
      "         856       0.07      0.57      0.12         7\n",
      "         857       0.23      0.65      0.34        89\n",
      "         858       0.23      0.57      0.32        21\n",
      "         859       0.09      0.38      0.14        13\n",
      "         860       0.00      0.00      0.00         3\n",
      "         861       0.17      0.31      0.22        13\n",
      "         862       0.06      0.24      0.09        21\n",
      "         863       0.13      0.78      0.22        23\n",
      "         864       0.03      0.23      0.05        22\n",
      "         865       0.00      0.00      0.00         4\n",
      "         866       0.25      0.82      0.38       271\n",
      "         867       0.02      0.09      0.03        11\n",
      "         868       0.01      0.12      0.02         8\n",
      "         869       0.03      0.20      0.06        15\n",
      "         870       0.08      0.17      0.11         6\n",
      "         871       0.20      0.60      0.30        10\n",
      "         872       0.34      0.91      0.50        11\n",
      "         873       0.08      1.00      0.14         1\n",
      "         874       0.00      0.00      0.00         2\n",
      "         875       0.00      0.00      0.00         1\n",
      "         876       0.24      0.80      0.37        66\n",
      "         877       0.35      0.68      0.46        22\n",
      "         878       0.17      0.33      0.22         6\n",
      "         879       0.18      0.70      0.28        44\n",
      "         880       0.14      0.63      0.23        90\n",
      "         881       0.36      0.86      0.50       292\n",
      "         882       0.15      0.59      0.24       107\n",
      "         883       0.37      0.83      0.51       103\n",
      "         884       0.35      0.76      0.48        92\n",
      "         885       0.07      0.45      0.12        20\n",
      "         886       0.11      0.35      0.16        48\n",
      "         887       0.11      0.58      0.19        24\n",
      "         888       0.12      0.38      0.18        16\n",
      "         889       0.09      0.69      0.16        32\n",
      "         890       0.19      0.43      0.26         7\n",
      "         891       0.05      0.34      0.08        32\n",
      "         892       0.07      0.52      0.13        46\n",
      "         893       0.00      0.00      0.00         6\n",
      "         894       0.23      0.51      0.32        37\n",
      "         895       0.17      0.61      0.26        49\n",
      "         896       0.09      0.50      0.16        22\n",
      "         897       0.00      0.00      0.00         4\n",
      "         898       0.07      0.50      0.12        40\n",
      "         899       0.09      0.47      0.15        36\n",
      "         900       0.54      0.79      0.64       392\n",
      "         901       0.20      0.50      0.29         2\n",
      "         902       0.00      0.00      0.00         2\n",
      "         903       0.06      0.21      0.10        24\n",
      "         904       0.17      0.63      0.27        97\n",
      "         905       0.35      0.79      0.48       135\n",
      "         906       0.13      0.59      0.21        82\n",
      "         907       0.34      0.85      0.49        73\n",
      "         908       0.13      0.79      0.22        24\n",
      "         909       0.10      0.40      0.16        10\n",
      "         910       0.39      0.91      0.55        45\n",
      "         911       0.32      0.74      0.44        76\n",
      "         912       0.11      0.45      0.18        11\n",
      "         913       0.38      0.73      0.50        45\n",
      "         914       0.25      0.72      0.37        25\n",
      "         915       0.32      0.78      0.45        89\n",
      "         916       0.26      0.67      0.37        21\n",
      "         917       0.25      0.75      0.37        79\n",
      "         918       0.07      0.40      0.11         5\n",
      "         919       0.23      0.79      0.36        89\n",
      "         920       0.08      0.25      0.12         8\n",
      "         921       0.00      0.00      0.00         5\n",
      "         922       0.11      1.00      0.20         1\n",
      "         923       0.02      0.40      0.04        15\n",
      "         924       0.19      0.73      0.31       190\n",
      "         925       0.08      0.60      0.14        88\n",
      "         926       0.04      0.44      0.08        39\n",
      "         927       0.08      0.21      0.12        14\n",
      "         928       0.33      0.75      0.46         4\n",
      "         929       0.10      0.35      0.16        37\n",
      "         930       0.11      0.62      0.18         8\n",
      "         931       0.18      0.62      0.27        53\n",
      "         932       0.16      0.64      0.26       101\n",
      "         933       0.00      0.00      0.00         7\n",
      "         934       0.08      0.22      0.11         9\n",
      "         935       0.11      0.50      0.17         4\n",
      "         936       0.36      0.96      0.52       260\n",
      "         937       0.06      0.36      0.11        84\n",
      "         938       0.16      0.43      0.23        28\n",
      "         939       0.11      0.63      0.18        30\n",
      "         940       0.09      0.56      0.16        25\n",
      "         941       0.33      0.82      0.47       169\n",
      "         942       0.00      0.00      0.00         6\n",
      "         943       0.00      0.00      0.00         2\n",
      "         944       0.08      0.33      0.12         3\n",
      "         945       0.02      0.14      0.04         7\n",
      "         946       0.46      0.83      0.59       132\n",
      "         947       0.23      0.77      0.35       335\n",
      "         948       0.08      0.57      0.14         7\n",
      "         949       0.13      0.25      0.17         8\n",
      "         950       0.05      0.29      0.09         7\n",
      "         951       0.49      0.88      0.63        67\n",
      "         952       0.01      0.20      0.02         5\n",
      "         953       0.09      0.78      0.15        18\n",
      "         954       0.00      0.00      0.00         1\n",
      "         955       0.04      0.18      0.06        33\n",
      "         956       0.19      0.59      0.28        44\n",
      "         957       0.12      0.49      0.19        59\n",
      "         958       0.17      0.68      0.27       155\n",
      "         959       0.05      0.17      0.07         6\n",
      "         960       0.11      0.80      0.20        54\n",
      "         961       0.06      0.11      0.08         9\n",
      "         962       0.16      0.73      0.26        98\n",
      "         963       0.36      0.85      0.50       507\n",
      "         964       0.22      0.69      0.34        81\n",
      "         965       0.08      0.40      0.13         5\n",
      "         966       0.01      0.11      0.02         9\n",
      "         967       0.18      0.67      0.29        48\n",
      "         968       0.12      0.52      0.20        23\n",
      "         969       0.20      0.64      0.31       135\n",
      "         970       0.00      0.00      0.00         9\n",
      "         971       0.03      0.27      0.06        15\n",
      "         972       0.03      0.22      0.05        23\n",
      "         973       0.26      0.61      0.36        38\n",
      "         974       0.16      0.60      0.25        99\n",
      "         975       0.07      0.47      0.12        36\n",
      "         976       0.19      0.60      0.29        65\n",
      "         977       0.15      0.64      0.24       166\n",
      "         978       0.00      0.00      0.00         2\n",
      "         979       0.72      0.98      0.83       611\n",
      "         980       0.72      0.92      0.81       208\n",
      "         981       0.22      0.76      0.34        92\n",
      "         982       0.00      0.00      0.00        12\n",
      "         983       0.32      0.77      0.45        43\n",
      "         984       0.51      0.93      0.66       568\n",
      "         985       0.16      0.79      0.27        43\n",
      "         986       0.01      0.40      0.02         5\n",
      "         987       0.46      0.86      0.60       101\n",
      "         988       0.09      0.58      0.16        26\n",
      "         989       0.07      0.63      0.12        19\n",
      "         990       0.03      0.30      0.06        10\n",
      "         991       0.15      0.63      0.25        89\n",
      "         992       0.00      0.00      0.00         1\n",
      "         993       0.42      0.86      0.57       113\n",
      "         994       0.12      0.46      0.20       171\n",
      "         995       0.25      0.72      0.37       114\n",
      "         996       0.08      0.50      0.14         2\n",
      "         997       0.44      0.86      0.58       236\n",
      "         998       0.00      0.00      0.00         3\n",
      "         999       0.09      0.39      0.15        31\n",
      "        1000       0.38      0.85      0.53       480\n",
      "        1001       0.11      0.47      0.18        60\n",
      "        1002       0.29      0.88      0.44       433\n",
      "        1003       0.11      0.49      0.18        76\n",
      "        1004       0.07      0.39      0.12        38\n",
      "        1005       0.00      0.00      0.00         4\n",
      "        1006       0.16      0.60      0.25       121\n",
      "        1007       0.03      0.20      0.05        10\n",
      "        1008       0.16      0.58      0.25        55\n",
      "        1009       0.12      0.50      0.20         6\n",
      "        1010       0.09      0.65      0.15        20\n",
      "        1011       0.05      0.67      0.10         3\n",
      "        1012       0.03      0.25      0.05         8\n",
      "        1013       0.02      0.09      0.04        11\n",
      "        1014       0.00      0.00      0.00         1\n",
      "        1015       0.00      0.00      0.00         7\n",
      "        1016       0.17      0.31      0.22        16\n",
      "        1017       0.22      0.70      0.33        23\n",
      "        1018       0.03      0.11      0.05         9\n",
      "        1019       0.17      0.70      0.27        90\n",
      "        1020       0.09      0.47      0.15       120\n",
      "        1021       0.34      0.85      0.49        87\n",
      "        1022       0.04      0.31      0.07        26\n",
      "        1023       0.07      0.33      0.12        21\n",
      "        1024       0.04      0.22      0.06        23\n",
      "        1025       0.28      0.63      0.39        35\n",
      "        1026       0.08      0.37      0.13        35\n",
      "        1027       0.06      0.38      0.11         8\n",
      "        1028       0.01      0.09      0.02        11\n",
      "        1029       0.11      0.20      0.14        15\n",
      "        1030       0.09      0.14      0.11        21\n",
      "        1031       0.03      0.12      0.04        25\n",
      "        1032       0.02      0.35      0.04        17\n",
      "        1033       0.01      0.08      0.03        12\n",
      "        1034       0.00      0.00      0.00         4\n",
      "        1035       0.54      0.82      0.65        55\n",
      "        1036       0.30      0.73      0.42        92\n",
      "        1037       0.10      0.53      0.17        72\n",
      "        1038       0.08      0.44      0.14        16\n",
      "        1039       0.00      0.00      0.00         4\n",
      "        1040       0.56      0.83      0.67         6\n",
      "        1041       0.17      0.49      0.25        55\n",
      "        1042       0.25      0.65      0.36        65\n",
      "        1043       0.14      0.43      0.21        30\n",
      "        1044       0.03      0.16      0.05        19\n",
      "        1045       0.02      0.18      0.03        22\n",
      "        1046       0.17      0.41      0.24        22\n",
      "        1047       0.09      0.41      0.15        27\n",
      "        1048       0.02      0.11      0.04         9\n",
      "        1049       0.31      0.36      0.33        11\n",
      "        1050       0.15      0.38      0.21         8\n",
      "        1051       0.15      0.29      0.20         7\n",
      "        1052       0.00      0.00      0.00         3\n",
      "        1053       0.10      0.43      0.16        14\n",
      "        1054       0.03      0.18      0.04        11\n",
      "        1055       0.16      0.39      0.23        18\n",
      "        1056       0.10      0.70      0.18        57\n",
      "        1057       0.54      0.95      0.69       750\n",
      "        1058       0.00      0.00      0.00        15\n",
      "        1059       0.05      0.36      0.09        36\n",
      "        1060       0.10      0.29      0.15         7\n",
      "        1061       0.04      0.13      0.06        15\n",
      "        1062       0.23      0.70      0.34        50\n",
      "        1063       0.08      1.00      0.14         1\n",
      "        1064       0.02      0.16      0.04        31\n",
      "        1065       0.17      0.56      0.26        16\n",
      "        1066       0.38      0.74      0.51        34\n",
      "        1067       0.25      0.81      0.39        42\n",
      "        1068       0.28      0.84      0.42        19\n",
      "        1069       0.25      0.73      0.37        22\n",
      "        1070       0.13      0.38      0.19         8\n",
      "        1071       0.07      0.48      0.12        58\n",
      "        1072       0.09      0.52      0.16        60\n",
      "        1073       0.02      0.19      0.03        21\n",
      "        1074       0.21      0.40      0.27        15\n",
      "        1075       0.00      0.00      0.00         9\n",
      "        1076       0.00      0.00      0.00         0\n",
      "        1077       0.00      0.00      0.00         0\n",
      "        1078       0.00      0.00      0.00         1\n",
      "        1079       0.00      0.00      0.00         1\n",
      "        1080       0.00      0.00      0.00         1\n",
      "        1081       0.00      0.00      0.00         0\n",
      "        1082       0.07      0.29      0.12        17\n",
      "        1083       0.00      0.00      0.00         1\n",
      "        1084       0.00      0.00      0.00         0\n",
      "        1085       0.00      0.00      0.00         0\n",
      "        1086       0.20      0.56      0.29         9\n",
      "        1087       0.50      0.67      0.57         3\n",
      "        1088       0.13      0.50      0.20        18\n",
      "        1089       0.00      0.00      0.00         3\n",
      "        1090       0.00      0.00      0.00         3\n",
      "        1091       0.00      0.00      0.00         1\n",
      "        1092       0.33      1.00      0.50         1\n",
      "        1093       0.00      0.00      0.00         0\n",
      "        1094       0.00      0.00      0.00         2\n",
      "        1095       0.00      0.00      0.00         0\n",
      "        1096       0.00      0.00      0.00         1\n",
      "        1097       0.00      0.00      0.00         1\n",
      "        1098       0.00      0.00      0.00         0\n",
      "        1099       0.00      0.00      0.00         0\n",
      "        1100       0.00      0.00      0.00         2\n",
      "        1101       0.00      0.00      0.00         0\n",
      "        1102       0.00      0.00      0.00         1\n",
      "        1103       0.07      0.43      0.12        51\n",
      "        1104       0.00      0.00      0.00         0\n",
      "        1105       0.00      0.00      0.00         0\n",
      "        1106       0.00      0.00      0.00         0\n",
      "        1107       0.00      0.00      0.00         2\n",
      "        1108       0.00      0.00      0.00         0\n",
      "        1109       0.00      0.00      0.00        10\n",
      "        1110       0.00      0.00      0.00         0\n",
      "        1111       0.12      0.50      0.20         2\n",
      "        1112       0.00      0.00      0.00         1\n",
      "        1113       0.00      0.00      0.00         0\n",
      "        1114       0.00      0.00      0.00         0\n",
      "        1115       0.00      0.00      0.00         1\n",
      "        1116       0.00      0.00      0.00         0\n",
      "        1117       0.00      0.00      0.00         1\n",
      "        1118       0.00      0.00      0.00         3\n",
      "        1119       0.00      0.00      0.00         1\n",
      "        1120       0.50      0.67      0.57         3\n",
      "        1121       0.35      0.80      0.49       396\n",
      "        1122       0.00      0.00      0.00         0\n",
      "        1123       0.40      0.57      0.47         7\n",
      "        1124       0.00      0.00      0.00         0\n",
      "        1125       0.00      0.00      0.00         1\n",
      "        1126       0.00      0.00      0.00         0\n",
      "        1127       0.00      0.00      0.00         1\n",
      "        1128       0.04      0.29      0.07        21\n",
      "        1129       0.00      0.00      0.00         0\n",
      "        1130       0.00      0.00      0.00         1\n",
      "        1131       0.00      0.00      0.00         0\n",
      "        1132       1.00      0.50      0.67         2\n",
      "        1133       0.12      0.59      0.20        63\n",
      "        1134       0.00      0.00      0.00         0\n",
      "        1135       0.00      0.00      0.00         0\n",
      "        1136       0.33      1.00      0.50         1\n",
      "        1137       0.00      0.00      0.00         0\n",
      "        1138       0.00      0.00      0.00         0\n",
      "        1139       0.00      0.00      0.00         3\n",
      "        1140       0.00      0.00      0.00         0\n",
      "        1141       0.00      0.00      0.00         0\n",
      "        1142       0.08      0.27      0.12        11\n",
      "        1143       0.20      0.33      0.25         6\n",
      "        1144       0.00      0.00      0.00         1\n",
      "        1145       0.00      0.00      0.00         2\n",
      "        1146       1.00      0.50      0.67         2\n",
      "        1147       0.00      0.00      0.00         9\n",
      "        1148       0.00      0.00      0.00         0\n",
      "        1149       0.00      0.00      0.00         0\n",
      "        1150       0.67      0.67      0.67         3\n",
      "        1151       0.12      0.47      0.19        15\n",
      "        1152       0.00      0.00      0.00         1\n",
      "        1153       0.00      0.00      0.00         0\n",
      "        1154       0.20      0.80      0.32         5\n",
      "        1155       0.00      0.00      0.00         0\n",
      "        1156       0.15      0.33      0.21         9\n",
      "        1157       0.00      0.00      0.00         1\n",
      "        1158       0.00      0.00      0.00         0\n",
      "        1159       0.00      0.00      0.00         2\n",
      "        1160       0.25      1.00      0.40         1\n",
      "        1161       0.00      0.00      0.00         1\n",
      "        1162       0.00      0.00      0.00         4\n",
      "        1163       0.00      0.00      0.00         0\n",
      "        1164       0.00      0.00      0.00         0\n",
      "        1165       0.19      0.50      0.28         8\n",
      "        1166       0.00      0.00      0.00         0\n",
      "        1167       0.00      0.00      0.00         0\n",
      "        1168       0.00      0.00      0.00         0\n",
      "        1169       0.33      1.00      0.50         1\n",
      "        1170       0.44      0.80      0.57         5\n",
      "        1171       0.00      0.00      0.00         1\n",
      "        1172       0.00      0.00      0.00         1\n",
      "        1173       0.50      0.67      0.57         3\n",
      "        1174       0.00      0.00      0.00         2\n",
      "        1175       1.00      0.50      0.67         2\n",
      "        1176       0.20      0.71      0.32        34\n",
      "        1177       0.00      0.00      0.00         1\n",
      "        1178       0.00      0.00      0.00         0\n",
      "        1179       0.00      0.00      0.00         0\n",
      "        1180       0.00      0.00      0.00         3\n",
      "        1181       0.00      0.00      0.00         1\n",
      "        1182       0.75      0.60      0.67         5\n",
      "        1183       0.18      0.42      0.25        12\n",
      "        1184       0.22      0.40      0.29         5\n",
      "        1185       0.00      0.00      0.00         0\n",
      "        1186       0.17      0.21      0.19        14\n",
      "        1187       0.00      0.00      0.00         1\n",
      "        1188       0.00      0.00      0.00         0\n",
      "        1189       0.33      1.00      0.50         4\n",
      "        1190       0.15      0.80      0.25         5\n",
      "        1191       0.30      1.00      0.46         6\n",
      "        1192       0.07      0.56      0.13         9\n",
      "        1193       0.00      0.00      0.00         1\n",
      "        1194       0.06      0.50      0.11         2\n",
      "        1195       0.24      0.67      0.35         6\n",
      "        1196       0.00      0.00      0.00         2\n",
      "        1197       0.00      0.00      0.00         7\n",
      "        1198       0.07      0.14      0.10         7\n",
      "        1199       0.08      0.50      0.13         2\n",
      "        1200       0.29      0.57      0.38         7\n",
      "        1201       0.00      0.00      0.00         4\n",
      "        1202       0.00      0.00      0.00         0\n",
      "        1203       0.24      0.83      0.37         6\n",
      "        1204       0.00      0.00      0.00         0\n",
      "        1205       0.33      0.50      0.40         2\n",
      "        1206       0.09      0.62      0.16        16\n",
      "        1207       0.00      0.00      0.00         0\n",
      "        1208       0.09      0.37      0.14        19\n",
      "        1209       0.29      0.64      0.40        14\n",
      "        1210       0.31      0.62      0.42         8\n",
      "        1211       0.00      0.00      0.00         0\n",
      "        1212       0.00      0.00      0.00         3\n",
      "        1213       0.00      0.00      0.00         2\n",
      "        1214       0.00      0.00      0.00         0\n",
      "        1215       0.00      0.00      0.00         3\n",
      "        1216       0.00      0.00      0.00         0\n",
      "        1217       0.18      0.50      0.26        16\n",
      "        1218       0.28      0.71      0.40        52\n",
      "        1219       0.67      0.67      0.67         3\n",
      "        1220       0.12      0.60      0.21       258\n",
      "        1221       0.04      0.35      0.07        20\n",
      "        1222       0.07      0.30      0.12        30\n",
      "        1223       0.19      0.69      0.30        16\n",
      "        1224       0.09      0.50      0.16       125\n",
      "        1225       0.07      0.40      0.12        25\n",
      "        1226       0.10      0.59      0.17        41\n",
      "        1227       0.28      0.70      0.40        10\n",
      "        1228       0.00      0.00      0.00         3\n",
      "        1229       0.00      0.00      0.00         4\n",
      "        1230       0.08      0.50      0.14         2\n",
      "        1231       0.09      0.33      0.14         3\n",
      "        1232       0.08      0.40      0.13         5\n",
      "        1233       0.07      0.36      0.12        11\n",
      "        1234       0.00      0.00      0.00         2\n",
      "        1235       0.00      0.00      0.00         9\n",
      "        1236       0.00      0.00      0.00         1\n",
      "        1237       0.00      0.00      0.00         0\n",
      "        1238       0.05      0.29      0.09        17\n",
      "        1239       0.07      0.40      0.12        10\n",
      "        1240       0.09      0.20      0.13         5\n",
      "        1241       0.00      0.00      0.00         0\n",
      "        1242       0.00      0.00      0.00         0\n",
      "        1243       0.14      1.00      0.25         1\n",
      "        1244       0.25      1.00      0.40         1\n",
      "        1245       0.00      0.00      0.00         0\n",
      "        1246       0.00      0.00      0.00         0\n",
      "        1247       0.00      0.00      0.00         6\n",
      "        1248       0.00      0.00      0.00         1\n",
      "        1249       0.00      0.00      0.00         0\n",
      "        1250       0.00      0.00      0.00         2\n",
      "        1251       0.10      0.29      0.15         7\n",
      "        1252       0.00      0.00      0.00         2\n",
      "        1253       0.07      0.21      0.10        24\n",
      "        1254       0.00      0.00      0.00         0\n",
      "        1255       0.00      0.00      0.00         2\n",
      "        1256       0.00      0.00      0.00         0\n",
      "        1257       0.00      0.00      0.00         0\n",
      "        1258       0.00      0.00      0.00         0\n",
      "        1259       0.50      0.50      0.50         4\n",
      "        1260       0.00      0.00      0.00         3\n",
      "        1261       0.00      0.00      0.00         0\n",
      "        1262       0.00      0.00      0.00         0\n",
      "        1263       0.14      0.47      0.22        17\n",
      "        1264       1.00      1.00      1.00         1\n",
      "        1265       0.00      0.00      0.00         1\n",
      "        1266       0.00      0.00      0.00         0\n",
      "        1267       0.07      0.31      0.12        59\n",
      "        1268       0.00      0.00      0.00         1\n",
      "        1269       0.00      0.00      0.00        10\n",
      "        1270       0.00      0.00      0.00         1\n",
      "        1271       0.08      0.30      0.13        10\n",
      "        1272       0.00      0.00      0.00         0\n",
      "        1273       0.00      0.00      0.00         2\n",
      "        1274       0.06      0.25      0.10         4\n",
      "        1275       0.00      0.00      0.00         3\n",
      "        1276       0.20      1.00      0.33         1\n",
      "        1277       0.00      0.00      0.00         2\n",
      "        1278       0.21      0.95      0.34       131\n",
      "        1279       0.00      0.00      0.00         5\n",
      "        1280       0.03      0.17      0.05         6\n",
      "        1281       0.00      0.00      0.00         0\n",
      "        1282       0.00      0.00      0.00         3\n",
      "        1283       0.34      0.82      0.48       214\n",
      "        1284       0.00      0.00      0.00         0\n",
      "        1285       0.00      0.00      0.00         0\n",
      "        1286       0.00      0.00      0.00         0\n",
      "        1287       0.00      0.00      0.00         0\n",
      "        1288       0.14      0.50      0.22        22\n",
      "        1289       0.00      0.00      0.00         0\n",
      "        1290       0.00      0.00      0.00         0\n",
      "        1291       0.00      0.00      0.00         0\n",
      "        1292       0.00      0.00      0.00         0\n",
      "        1293       0.54      0.90      0.67       621\n",
      "        1294       0.00      0.00      0.00         0\n",
      "        1295       0.00      0.00      0.00         0\n",
      "        1296       1.00      0.40      0.57        10\n",
      "        1297       0.00      0.00      0.00         1\n",
      "        1298       0.00      0.00      0.00         0\n",
      "        1299       0.14      0.25      0.18         4\n",
      "        1300       0.00      0.00      0.00         0\n",
      "        1301       0.00      0.00      0.00         0\n",
      "        1302       0.00      0.00      0.00         0\n",
      "        1303       0.00      0.00      0.00         1\n",
      "        1304       0.00      0.00      0.00         0\n",
      "        1305       0.00      0.00      0.00         1\n",
      "        1306       0.00      0.00      0.00         0\n",
      "        1307       0.00      0.00      0.00         1\n",
      "        1308       0.02      0.40      0.03         5\n",
      "        1309       0.00      0.00      0.00         1\n",
      "        1310       0.00      0.00      0.00         1\n",
      "        1311       0.00      0.00      0.00         1\n",
      "        1312       0.00      0.00      0.00         0\n",
      "        1313       0.08      0.36      0.13        22\n",
      "        1314       0.06      0.25      0.09        24\n",
      "        1315       0.00      0.00      0.00         0\n",
      "        1316       0.09      0.40      0.15        80\n",
      "        1317       0.04      0.12      0.06        43\n",
      "        1318       0.48      0.87      0.62       205\n",
      "        1319       0.00      0.00      0.00         0\n",
      "        1320       0.00      0.00      0.00         1\n",
      "        1321       0.13      0.53      0.21        40\n",
      "        1322       0.00      0.00      0.00         0\n",
      "        1323       0.00      0.00      0.00         0\n",
      "        1324       0.14      0.61      0.23        31\n",
      "        1325       0.07      0.37      0.12        27\n",
      "        1326       0.00      0.00      0.00         0\n",
      "        1327       0.00      0.00      0.00         2\n",
      "        1328       0.00      0.00      0.00         7\n",
      "        1329       0.00      0.00      0.00         4\n",
      "        1330       0.00      0.00      0.00         2\n",
      "        1331       0.00      0.00      0.00         0\n",
      "        1332       0.00      0.00      0.00         3\n",
      "        1333       0.00      0.00      0.00         1\n",
      "        1334       0.00      0.00      0.00         0\n",
      "        1335       0.00      0.00      0.00         3\n",
      "        1336       0.00      0.00      0.00         0\n",
      "        1337       0.00      0.00      0.00         1\n",
      "        1338       0.00      0.00      0.00         0\n",
      "        1339       0.00      0.00      0.00         1\n",
      "        1340       0.00      0.00      0.00         0\n",
      "        1341       0.00      0.00      0.00         6\n",
      "        1342       0.00      0.00      0.00         1\n",
      "        1343       0.00      0.00      0.00         2\n",
      "        1344       0.00      0.00      0.00         0\n",
      "        1345       0.21      0.75      0.33         4\n",
      "        1346       0.00      0.00      0.00         2\n",
      "        1347       0.00      0.00      0.00         0\n",
      "        1348       0.00      0.00      0.00         4\n",
      "        1349       0.00      0.00      0.00         1\n",
      "        1350       0.00      0.00      0.00         0\n",
      "        1351       0.00      0.00      0.00         2\n",
      "        1352       0.00      0.00      0.00         0\n",
      "        1353       0.33      0.33      0.33         3\n",
      "        1354       0.10      1.00      0.18         1\n",
      "        1355       0.00      0.00      0.00         0\n",
      "        1356       0.00      0.00      0.00         0\n",
      "        1357       0.00      0.00      0.00         3\n",
      "        1358       0.05      0.33      0.09        18\n",
      "        1359       0.00      0.00      0.00         5\n",
      "        1360       0.07      0.34      0.12        29\n",
      "        1361       0.14      0.89      0.25        55\n",
      "        1362       0.07      0.20      0.11        15\n",
      "        1363       0.03      0.27      0.06        15\n",
      "        1364       0.00      0.00      0.00         3\n",
      "        1365       0.00      0.00      0.00         3\n",
      "        1366       0.08      0.25      0.12         4\n",
      "        1367       0.02      0.10      0.03        10\n",
      "        1368       0.14      0.71      0.24         7\n",
      "        1369       0.00      0.00      0.00         2\n",
      "        1370       0.03      0.27      0.06        15\n",
      "        1371       0.00      0.00      0.00         3\n",
      "        1372       0.00      0.00      0.00         0\n",
      "        1373       0.00      0.00      0.00         2\n",
      "        1374       0.08      0.33      0.13         3\n",
      "        1375       0.06      0.25      0.10         4\n",
      "        1376       0.00      0.00      0.00         0\n",
      "        1377       0.00      0.00      0.00         0\n",
      "        1378       0.33      0.50      0.40         2\n",
      "        1379       0.00      0.00      0.00         0\n",
      "        1380       0.00      0.00      0.00         2\n",
      "        1381       0.25      0.20      0.22         5\n",
      "        1382       0.00      0.00      0.00         2\n",
      "        1383       0.00      0.00      0.00         0\n",
      "        1384       0.00      0.00      0.00         0\n",
      "        1385       0.00      0.00      0.00         0\n",
      "        1386       0.01      0.09      0.02        11\n",
      "        1387       0.52      0.89      0.66        83\n",
      "        1388       0.14      0.55      0.22        11\n",
      "        1389       0.13      0.69      0.22       176\n",
      "        1390       0.32      0.99      0.48        68\n",
      "        1391       0.00      0.00      0.00         0\n",
      "        1392       0.40      0.83      0.54        23\n",
      "        1393       0.00      0.00      0.00         0\n",
      "        1394       0.00      0.00      0.00         0\n",
      "        1395       0.12      0.20      0.15        15\n",
      "        1396       0.00      0.00      0.00         0\n",
      "        1397       0.00      0.00      0.00         1\n",
      "        1398       0.11      0.40      0.17        10\n",
      "        1399       0.00      0.00      0.00         0\n",
      "        1400       0.05      0.59      0.10        17\n",
      "        1401       0.00      0.00      0.00         0\n",
      "        1402       0.00      0.00      0.00         0\n",
      "        1403       0.00      0.00      0.00         1\n",
      "        1404       0.00      0.00      0.00         0\n",
      "        1405       0.06      0.12      0.08         8\n",
      "        1406       0.00      0.00      0.00         0\n",
      "        1407       0.00      0.00      0.00         1\n",
      "        1408       0.00      0.00      0.00         0\n",
      "        1409       0.28      0.78      0.42       100\n",
      "        1410       0.00      0.00      0.00         1\n",
      "        1411       0.00      0.00      0.00         0\n",
      "        1412       0.20      1.00      0.33         1\n",
      "        1413       0.00      0.00      0.00         0\n",
      "        1414       0.25      0.44      0.32         9\n",
      "        1415       0.00      0.00      0.00         0\n",
      "        1416       0.09      0.44      0.14        27\n",
      "        1417       0.00      0.00      0.00         0\n",
      "        1418       0.00      0.00      0.00         0\n",
      "        1419       0.00      0.00      0.00         0\n",
      "        1420       0.00      0.00      0.00         0\n",
      "        1421       0.00      0.00      0.00         1\n",
      "        1422       0.00      0.00      0.00         1\n",
      "        1423       0.00      0.00      0.00         5\n",
      "        1424       0.10      0.38      0.16        24\n",
      "        1425       0.00      0.00      0.00         1\n",
      "        1426       0.00      0.00      0.00         1\n",
      "        1427       0.00      0.00      0.00         0\n",
      "        1428       0.00      0.00      0.00         5\n",
      "        1429       0.08      0.62      0.14        13\n",
      "        1430       0.01      0.17      0.02         6\n",
      "        1431       0.10      0.50      0.16         8\n",
      "        1432       0.17      0.60      0.27        10\n",
      "        1433       0.14      0.50      0.22        12\n",
      "        1434       0.12      0.62      0.20        13\n",
      "        1435       0.00      0.00      0.00         0\n",
      "        1436       0.05      0.56      0.10         9\n",
      "        1437       0.00      0.00      0.00         0\n",
      "        1438       0.17      1.00      0.29         2\n",
      "        1439       0.00      0.00      0.00         0\n",
      "        1440       0.00      0.00      0.00         0\n",
      "        1441       0.00      0.00      0.00         0\n",
      "        1442       0.11      0.50      0.19        16\n",
      "        1443       0.00      0.00      0.00         1\n",
      "        1444       0.00      0.00      0.00         0\n",
      "        1445       0.00      0.00      0.00         0\n",
      "        1446       0.00      0.00      0.00         1\n",
      "        1447       0.00      0.00      0.00         0\n",
      "        1448       0.09      0.51      0.16        47\n",
      "        1449       0.00      0.00      0.00         4\n",
      "        1450       0.18      0.68      0.29       116\n",
      "        1451       0.00      0.00      0.00         0\n",
      "        1452       0.19      0.60      0.29        70\n",
      "        1453       0.00      0.00      0.00         1\n",
      "        1454       0.00      0.00      0.00         0\n",
      "        1455       0.12      0.14      0.13         7\n",
      "        1456       0.09      0.65      0.16        52\n",
      "        1457       0.07      0.60      0.13        68\n",
      "        1458       0.07      0.47      0.13        17\n",
      "        1459       0.04      0.52      0.08        23\n",
      "        1460       0.09      0.65      0.15        51\n",
      "        1461       0.10      0.57      0.17        42\n",
      "        1462       0.05      0.42      0.08        26\n",
      "        1463       0.06      0.55      0.11        40\n",
      "        1464       0.07      0.59      0.13        32\n",
      "        1465       0.05      0.44      0.09        43\n",
      "        1466       0.17      0.63      0.26        95\n",
      "        1467       0.05      0.55      0.10        55\n",
      "        1468       0.08      0.57      0.14        46\n",
      "        1469       0.12      0.69      0.20       159\n",
      "        1470       0.13      0.79      0.23       146\n",
      "        1471       0.07      0.56      0.12        84\n",
      "        1472       0.14      0.74      0.23        98\n",
      "        1473       0.09      0.60      0.16        77\n",
      "        1474       0.19      0.77      0.30       179\n",
      "        1475       0.12      0.63      0.20       112\n",
      "        1476       0.07      0.65      0.12        55\n",
      "        1477       0.04      0.24      0.06        25\n",
      "        1478       0.07      0.50      0.12         2\n",
      "        1479       0.00      0.00      0.00         2\n",
      "        1480       0.00      0.00      0.00         1\n",
      "        1481       0.00      0.00      0.00         0\n",
      "        1482       0.00      0.00      0.00         2\n",
      "        1483       0.00      0.00      0.00         0\n",
      "        1484       0.00      0.00      0.00         3\n",
      "        1485       0.00      0.00      0.00         3\n",
      "        1486       0.00      0.00      0.00         1\n",
      "        1487       0.54      0.86      0.66       682\n",
      "        1488       0.00      0.00      0.00         0\n",
      "        1489       0.00      0.00      0.00         1\n",
      "        1490       0.00      0.00      0.00         1\n",
      "        1491       0.08      0.50      0.14        20\n",
      "        1492       0.00      0.00      0.00         1\n",
      "        1493       0.00      0.00      0.00         3\n",
      "        1494       0.50      0.25      0.33         4\n",
      "        1495       0.05      0.29      0.08         7\n",
      "        1496       0.00      0.00      0.00         0\n",
      "        1497       0.04      0.14      0.06         7\n",
      "        1498       0.00      0.00      0.00         0\n",
      "        1499       0.00      0.00      0.00         3\n",
      "        1500       0.24      0.44      0.31        16\n",
      "        1501       0.00      0.00      0.00         7\n",
      "        1502       0.00      0.00      0.00         0\n",
      "        1503       0.18      0.58      0.28        57\n",
      "        1504       0.00      0.00      0.00         2\n",
      "        1505       0.00      0.00      0.00        12\n",
      "        1506       0.00      0.00      0.00         0\n",
      "        1507       0.00      0.00      0.00         1\n",
      "        1508       0.00      0.00      0.00         1\n",
      "        1509       0.25      0.79      0.38       143\n",
      "        1510       0.00      0.00      0.00         0\n",
      "        1511       0.00      0.00      0.00         2\n",
      "        1512       0.00      0.00      0.00         2\n",
      "        1513       0.20      1.00      0.33         1\n",
      "        1514       0.00      0.00      0.00         1\n",
      "        1515       0.00      0.00      0.00         1\n",
      "        1516       0.18      0.80      0.30         5\n",
      "        1517       0.16      0.75      0.26         4\n",
      "        1518       0.00      0.00      0.00         0\n",
      "        1519       0.00      0.00      0.00         0\n",
      "        1520       0.00      0.00      0.00         0\n",
      "        1521       0.17      0.50      0.25         2\n",
      "        1522       0.00      0.00      0.00         1\n",
      "        1523       0.28      0.67      0.39        15\n",
      "        1524       0.00      0.00      0.00         0\n",
      "        1525       0.00      0.00      0.00         1\n",
      "        1526       0.00      0.00      0.00         1\n",
      "        1527       0.00      0.00      0.00         0\n",
      "        1528       0.00      0.00      0.00         0\n",
      "        1529       0.00      0.00      0.00         0\n",
      "        1530       0.00      0.00      0.00         2\n",
      "        1531       0.00      0.00      0.00         1\n",
      "        1532       0.00      0.00      0.00         0\n",
      "        1533       0.12      0.33      0.17        36\n",
      "        1534       0.00      0.00      0.00         0\n",
      "        1535       0.06      0.43      0.10         7\n",
      "        1536       0.04      0.21      0.07        14\n",
      "        1537       0.26      0.74      0.39        97\n",
      "        1538       0.00      0.00      0.00         0\n",
      "        1539       0.00      0.00      0.00         2\n",
      "        1540       0.00      0.00      0.00        21\n",
      "        1541       0.24      0.64      0.35       129\n",
      "        1542       0.00      0.00      0.00         6\n",
      "        1543       0.00      0.00      0.00         8\n",
      "        1544       0.02      0.21      0.03        14\n",
      "        1545       0.13      0.50      0.21        34\n",
      "        1546       0.58      0.88      0.70       225\n",
      "        1547       0.01      0.14      0.02        22\n",
      "        1548       0.23      0.84      0.36       474\n",
      "        1549       0.07      0.39      0.12        18\n",
      "        1550       0.05      0.09      0.06        11\n",
      "        1551       0.00      0.00      0.00         3\n",
      "        1552       0.07      0.33      0.12         9\n",
      "        1553       0.09      0.38      0.15        21\n",
      "        1554       0.06      0.61      0.11        36\n",
      "        1555       0.10      0.64      0.18       104\n",
      "        1556       0.22      0.73      0.34       153\n",
      "        1557       0.12      0.32      0.18        25\n",
      "        1558       0.06      0.35      0.10        20\n",
      "        1559       0.00      0.00      0.00         4\n",
      "        1560       0.11      0.67      0.18        72\n",
      "        1561       0.35      0.90      0.50       457\n",
      "        1562       0.00      0.00      0.00         8\n",
      "        1563       0.20      1.00      0.33         1\n",
      "        1564       0.10      0.25      0.14         4\n",
      "        1565       0.08      0.47      0.14        15\n",
      "        1566       0.00      0.00      0.00         4\n",
      "        1567       0.05      0.29      0.09        21\n",
      "        1568       0.12      0.52      0.20        27\n",
      "        1569       0.95      0.97      0.96       587\n",
      "        1570       0.24      0.88      0.38         8\n",
      "        1571       0.06      0.25      0.10         4\n",
      "        1572       0.14      0.59      0.23        27\n",
      "        1573       0.18      0.53      0.27        30\n",
      "        1574       0.18      0.68      0.29        41\n",
      "        1575       0.10      0.57      0.16        37\n",
      "        1576       0.15      0.51      0.23        39\n",
      "        1577       0.15      0.56      0.24        54\n",
      "        1578       0.30      0.67      0.41        36\n",
      "        1579       0.11      0.58      0.19        98\n",
      "        1580       0.20      0.58      0.30        24\n",
      "        1581       0.06      0.36      0.10        11\n",
      "        1582       0.00      0.00      0.00         2\n",
      "        1583       0.09      0.38      0.14         8\n",
      "        1584       0.25      0.21      0.23        14\n",
      "        1585       0.11      0.59      0.18        46\n",
      "        1586       0.12      0.55      0.19        75\n",
      "        1587       0.37      0.89      0.52       148\n",
      "        1588       0.17      0.70      0.27        44\n",
      "        1589       0.16      0.33      0.22        18\n",
      "        1590       0.00      0.00      0.00         1\n",
      "        1591       0.09      0.56      0.16        90\n",
      "        1592       0.02      0.09      0.03        11\n",
      "        1593       0.10      0.49      0.16        90\n",
      "        1594       0.03      0.09      0.05        11\n",
      "        1595       0.07      0.33      0.12        12\n",
      "        1596       0.38      0.79      0.51        14\n",
      "        1597       0.14      0.60      0.23        53\n",
      "        1598       0.12      0.23      0.15        22\n",
      "        1599       0.05      0.18      0.08        17\n",
      "        1600       0.04      0.18      0.07        11\n",
      "        1601       0.05      0.33      0.09         9\n",
      "        1602       0.03      0.15      0.04        13\n",
      "        1603       0.03      0.22      0.05         9\n",
      "        1604       0.07      0.22      0.10        18\n",
      "        1605       0.00      0.00      0.00         5\n",
      "        1606       0.15      0.33      0.20        15\n",
      "        1607       0.32      0.79      0.45        61\n",
      "        1608       0.07      0.47      0.13        17\n",
      "        1609       0.09      0.41      0.15        17\n",
      "        1610       0.04      0.35      0.07        17\n",
      "        1611       0.01      0.09      0.02        11\n",
      "        1612       0.16      0.60      0.25        25\n",
      "        1613       0.02      0.14      0.03         7\n",
      "        1614       0.07      0.59      0.13        27\n",
      "        1615       0.13      0.55      0.21        29\n",
      "        1616       0.12      0.50      0.19         4\n",
      "        1617       0.02      0.09      0.04        11\n",
      "        1618       0.00      0.00      0.00         1\n",
      "        1619       0.21      0.73      0.32       143\n",
      "        1620       0.08      0.37      0.13        19\n",
      "        1621       0.05      0.27      0.08        15\n",
      "        1622       0.07      0.38      0.12        52\n",
      "        1623       0.00      0.00      0.00         2\n",
      "        1624       0.00      0.00      0.00         1\n",
      "        1625       0.04      0.14      0.07        14\n",
      "        1626       0.04      0.20      0.06        25\n",
      "        1627       0.05      0.17      0.07        23\n",
      "        1628       0.13      0.71      0.23        92\n",
      "        1629       0.23      0.68      0.35        38\n",
      "        1630       0.00      0.00      0.00         4\n",
      "        1631       0.15      0.40      0.22         5\n",
      "        1632       0.12      0.52      0.20       103\n",
      "        1633       0.18      0.29      0.22        17\n",
      "        1634       0.88      0.98      0.93      1059\n",
      "        1635       0.12      0.62      0.20         8\n",
      "        1636       0.21      0.65      0.31       139\n",
      "        1637       0.14      0.35      0.20        20\n",
      "        1638       0.19      0.65      0.29        52\n",
      "        1639       0.21      0.63      0.31        63\n",
      "        1640       0.00      0.00      0.00         1\n",
      "        1641       0.00      0.00      0.00         5\n",
      "        1642       0.08      0.29      0.12         7\n",
      "        1643       0.12      0.63      0.19        79\n",
      "        1644       0.15      0.42      0.22        64\n",
      "        1645       0.19      0.55      0.28        66\n",
      "        1646       0.07      0.28      0.11        18\n",
      "        1647       0.01      0.07      0.01        14\n",
      "        1648       0.36      0.76      0.48        82\n",
      "        1649       0.16      0.41      0.23        44\n",
      "        1650       0.07      0.40      0.12        10\n",
      "        1651       0.07      0.28      0.12        32\n",
      "        1652       0.01      0.06      0.01        16\n",
      "        1653       0.34      0.83      0.48        63\n",
      "        1654       0.20      0.43      0.27         7\n",
      "        1655       0.00      0.00      0.00         0\n",
      "        1656       0.00      0.00      0.00         3\n",
      "        1657       0.00      0.00      0.00         6\n",
      "        1658       0.00      0.00      0.00         7\n",
      "        1659       0.13      0.45      0.21        42\n",
      "        1660       0.12      0.45      0.19        11\n",
      "        1661       0.18      0.85      0.30       105\n",
      "        1662       0.13      0.43      0.20        30\n",
      "        1663       0.00      0.00      0.00         0\n",
      "        1664       0.00      0.00      0.00         2\n",
      "        1665       0.23      0.64      0.34        11\n",
      "        1666       0.12      0.61      0.20       130\n",
      "        1667       0.09      0.50      0.15         6\n",
      "        1668       0.14      0.50      0.22         2\n",
      "        1669       0.20      0.20      0.20         5\n",
      "        1670       0.50      0.75      0.60         8\n",
      "        1671       0.31      0.79      0.45        19\n",
      "        1672       0.21      0.47      0.29        19\n",
      "        1673       0.12      0.50      0.20        12\n",
      "        1674       0.32      0.76      0.45        50\n",
      "        1675       0.20      0.56      0.29        27\n",
      "        1676       0.00      0.00      0.00         7\n",
      "        1677       0.22      0.71      0.34        24\n",
      "        1678       0.19      0.56      0.28        27\n",
      "        1679       0.09      0.38      0.14        16\n",
      "        1680       0.04      0.18      0.07        17\n",
      "        1681       0.00      0.00      0.00         4\n",
      "        1682       0.31      0.79      0.45        66\n",
      "        1683       0.13      0.43      0.20        14\n",
      "        1684       0.10      0.40      0.16        25\n",
      "        1685       0.02      0.32      0.05        19\n",
      "        1686       0.06      0.40      0.10        10\n",
      "        1687       0.16      0.56      0.25        57\n",
      "        1688       0.05      0.17      0.08         6\n",
      "        1689       0.12      0.64      0.20        55\n",
      "        1690       0.04      0.24      0.07        17\n",
      "        1691       0.03      0.24      0.05        17\n",
      "        1692       0.09      0.33      0.14        12\n",
      "        1693       0.09      0.47      0.15       150\n",
      "        1694       0.16      0.74      0.27       133\n",
      "        1695       0.24      0.66      0.35        96\n",
      "        1696       0.00      0.00      0.00         3\n",
      "        1697       0.09      0.45      0.15        22\n",
      "        1698       0.03      0.38      0.05        16\n",
      "        1699       0.00      0.00      0.00         3\n",
      "        1700       0.04      0.27      0.07        11\n",
      "        1701       0.00      0.00      0.00         0\n",
      "        1702       0.10      0.55      0.16        22\n",
      "        1703       0.05      0.36      0.08        14\n",
      "        1704       0.03      0.10      0.05        10\n",
      "        1705       0.02      0.17      0.04         6\n",
      "        1706       0.00      0.00      0.00         3\n",
      "        1707       0.11      0.40      0.17         5\n",
      "        1708       0.09      0.14      0.11         7\n",
      "        1709       0.00      0.00      0.00         0\n",
      "        1710       0.00      0.00      0.00         1\n",
      "        1711       0.15      0.53      0.23        30\n",
      "        1712       0.21      0.82      0.34        34\n",
      "        1713       0.00      0.00      0.00         1\n",
      "        1714       0.34      0.80      0.48        41\n",
      "        1715       0.16      0.61      0.26        18\n",
      "        1716       0.31      0.56      0.40         9\n",
      "        1717       0.04      0.08      0.06        13\n",
      "        1718       0.00      0.00      0.00         3\n",
      "        1719       0.27      0.62      0.38        16\n",
      "        1720       0.09      0.27      0.13        11\n",
      "        1721       0.20      0.68      0.31        72\n",
      "        1722       0.08      0.41      0.13        29\n",
      "        1723       0.18      0.47      0.26        34\n",
      "        1724       0.09      0.42      0.15        45\n",
      "        1725       0.18      0.31      0.22        36\n",
      "        1726       0.00      0.00      0.00         0\n",
      "        1727       0.56      0.91      0.70       121\n",
      "        1728       0.38      0.95      0.54       173\n",
      "        1729       0.00      0.00      0.00         0\n",
      "        1730       0.09      0.53      0.15        40\n",
      "        1731       0.18      0.67      0.29        88\n",
      "        1732       0.27      0.86      0.41         7\n",
      "        1733       0.24      0.70      0.36        60\n",
      "        1734       0.21      0.77      0.33        65\n",
      "        1735       0.23      0.72      0.35        57\n",
      "        1736       0.34      0.78      0.47        78\n",
      "        1737       0.32      0.78      0.45        96\n",
      "        1738       0.20      0.55      0.30        65\n",
      "        1739       0.09      0.50      0.15        44\n",
      "        1740       0.80      0.67      0.73         6\n",
      "        1741       0.33      0.86      0.47        51\n",
      "        1742       0.00      0.00      0.00         4\n",
      "        1743       0.80      1.00      0.89         4\n",
      "        1744       0.15      0.69      0.24        58\n",
      "        1745       0.50      0.67      0.57        12\n",
      "        1746       0.31      0.83      0.46        41\n",
      "        1747       0.00      0.00      0.00         8\n",
      "        1748       0.17      0.86      0.29        14\n",
      "        1749       0.01      0.08      0.02        12\n",
      "        1750       0.00      0.00      0.00         1\n",
      "        1751       0.27      0.81      0.41        42\n",
      "        1752       0.09      0.53      0.15        17\n",
      "        1753       0.43      1.00      0.60         3\n",
      "        1754       0.20      0.53      0.29        17\n",
      "        1755       0.22      0.80      0.34        49\n",
      "        1756       0.40      1.00      0.57         2\n",
      "        1757       0.00      0.00      0.00         0\n",
      "        1758       0.00      0.00      0.00         0\n",
      "        1759       0.29      0.83      0.43         6\n",
      "        1760       0.36      0.95      0.53       199\n",
      "        1761       0.00      0.00      0.00         0\n",
      "        1762       0.29      0.62      0.40         8\n",
      "        1763       0.53      0.90      0.67        10\n",
      "        1764       0.30      0.89      0.45        76\n",
      "        1765       0.00      0.00      0.00         0\n",
      "        1766       0.64      0.94      0.76        32\n",
      "        1767       0.37      0.84      0.52        38\n",
      "        1768       0.00      0.00      0.00         0\n",
      "        1769       0.33      1.00      0.50         1\n",
      "        1770       0.00      0.00      0.00         2\n",
      "        1771       0.76      0.89      0.82        28\n",
      "        1772       0.06      0.44      0.11        55\n",
      "        1773       0.49      0.88      0.63       121\n",
      "        1774       0.06      0.17      0.09         6\n",
      "        1775       0.67      0.75      0.71         8\n",
      "        1776       0.24      0.80      0.37        61\n",
      "        1777       0.01      0.08      0.01        12\n",
      "        1778       0.12      0.46      0.19        84\n",
      "        1779       0.10      0.56      0.17        32\n",
      "        1780       0.16      0.65      0.26        55\n",
      "        1781       0.04      0.22      0.07         9\n",
      "        1782       0.24      0.74      0.37        90\n",
      "        1783       0.25      0.77      0.38       105\n",
      "        1784       0.10      0.36      0.15        25\n",
      "        1785       0.08      0.33      0.13         6\n",
      "        1786       0.28      0.71      0.40        51\n",
      "        1787       0.22      0.74      0.34       179\n",
      "        1788       0.15      0.38      0.22        16\n",
      "        1789       0.07      0.33      0.11        40\n",
      "        1790       0.15      0.61      0.25        23\n",
      "        1791       0.05      0.29      0.08        14\n",
      "        1792       0.07      0.46      0.12        41\n",
      "        1793       0.00      0.00      0.00        20\n",
      "        1794       0.00      0.00      0.00         1\n",
      "        1795       0.00      0.00      0.00         1\n",
      "        1796       0.21      0.80      0.33        10\n",
      "        1797       0.09      0.48      0.15        61\n",
      "        1798       0.08      0.23      0.12        13\n",
      "        1799       0.17      0.54      0.25        35\n",
      "        1800       0.00      0.00      0.00         2\n",
      "        1801       0.06      0.22      0.09         9\n",
      "        1802       0.32      0.83      0.46        54\n",
      "        1803       0.07      0.25      0.11         8\n",
      "        1804       0.34      0.83      0.48       218\n",
      "        1805       0.53      0.89      0.66       697\n",
      "        1806       0.29      0.79      0.42       312\n",
      "        1807       0.35      0.87      0.50       399\n",
      "        1808       0.23      0.66      0.35        35\n",
      "        1809       0.25      0.73      0.38       203\n",
      "        1810       0.13      0.58      0.21        64\n",
      "        1811       0.20      0.61      0.30       107\n",
      "        1812       0.05      0.43      0.09        14\n",
      "        1813       0.15      0.67      0.24       105\n",
      "        1814       0.09      0.57      0.16        30\n",
      "        1815       0.00      0.00      0.00         2\n",
      "        1816       0.21      0.55      0.31        11\n",
      "        1817       0.22      0.50      0.31         8\n",
      "        1818       0.00      0.00      0.00        11\n",
      "        1819       0.44      0.89      0.59       158\n",
      "        1820       0.00      0.00      0.00        13\n",
      "        1821       0.02      0.17      0.03         6\n",
      "        1822       0.20      0.66      0.31        88\n",
      "        1823       0.45      0.93      0.61       482\n",
      "        1824       0.31      0.74      0.44       100\n",
      "        1825       0.19      0.57      0.29       120\n",
      "        1826       0.07      0.44      0.12        66\n",
      "        1827       0.12      0.25      0.17         4\n",
      "        1828       0.17      0.67      0.27        58\n",
      "        1829       0.25      0.81      0.39       204\n",
      "        1830       0.09      0.40      0.15        47\n",
      "        1831       0.14      0.51      0.22        75\n",
      "        1832       0.35      0.86      0.49       307\n",
      "        1833       0.30      0.82      0.44       284\n",
      "        1834       0.04      0.33      0.07        12\n",
      "        1835       0.70      0.91      0.79       223\n",
      "        1836       0.06      0.30      0.10        10\n",
      "        1837       0.00      0.00      0.00         1\n",
      "        1838       0.11      0.48      0.18        29\n",
      "        1839       0.14      0.52      0.22        21\n",
      "        1840       0.02      0.11      0.03         9\n",
      "        1841       0.11      0.61      0.19        31\n",
      "        1842       0.06      0.38      0.11        29\n",
      "        1843       0.09      0.55      0.15        20\n",
      "        1844       0.00      0.00      0.00         4\n",
      "        1845       0.00      0.00      0.00         2\n",
      "        1846       0.02      0.17      0.04         6\n",
      "        1847       0.21      0.82      0.33        61\n",
      "        1848       0.15      0.74      0.26        42\n",
      "        1849       0.07      0.39      0.12        31\n",
      "        1850       0.18      0.71      0.29        87\n",
      "        1851       0.22      0.72      0.34       117\n",
      "        1852       0.07      0.75      0.13         8\n",
      "        1853       0.29      0.81      0.43       176\n",
      "        1854       0.00      0.00      0.00         4\n",
      "        1855       0.00      0.00      0.00         3\n",
      "        1856       0.11      0.34      0.17        29\n",
      "        1857       0.01      0.18      0.02        11\n",
      "        1858       0.00      0.00      0.00         2\n",
      "        1859       0.10      0.36      0.16        33\n",
      "        1860       0.45      0.89      0.60       261\n",
      "        1861       0.13      0.49      0.21        43\n",
      "        1862       0.21      0.80      0.33         5\n",
      "        1863       0.38      0.43      0.40         7\n",
      "        1864       0.06      0.30      0.10        69\n",
      "        1865       0.17      0.51      0.25        79\n",
      "        1866       0.00      0.00      0.00         4\n",
      "        1867       0.26      0.79      0.40       227\n",
      "        1868       0.08      0.40      0.13        10\n",
      "        1869       0.00      0.00      0.00         1\n",
      "        1870       0.07      0.41      0.12        32\n",
      "        1871       0.17      0.43      0.24        23\n",
      "        1872       0.06      0.50      0.11         6\n",
      "        1873       0.00      0.00      0.00         2\n",
      "        1874       0.00      0.00      0.00         3\n",
      "        1875       0.00      0.00      0.00         3\n",
      "        1876       0.04      0.17      0.07        18\n",
      "        1877       0.26      0.65      0.37        17\n",
      "        1878       0.11      0.31      0.17        16\n",
      "        1879       0.45      0.84      0.58       158\n",
      "        1880       0.06      0.38      0.11        16\n",
      "        1881       0.15      0.61      0.24        82\n",
      "        1882       0.02      0.26      0.04        19\n",
      "        1883       0.06      0.38      0.11        48\n",
      "        1884       0.00      0.00      0.00         6\n",
      "        1885       0.24      0.72      0.36        83\n",
      "        1886       0.27      0.69      0.38        51\n",
      "        1887       0.13      0.64      0.21        73\n",
      "        1888       0.25      0.75      0.38        69\n",
      "        1889       0.27      0.76      0.40        59\n",
      "        1890       0.31      0.63      0.42        27\n",
      "        1891       0.33      0.83      0.48        12\n",
      "        1892       0.06      0.26      0.09        27\n",
      "        1893       0.29      0.70      0.41        43\n",
      "        1894       0.18      0.47      0.26        15\n",
      "        1895       0.28      0.80      0.42       143\n",
      "        1896       0.19      0.69      0.30        58\n",
      "        1897       0.12      0.64      0.20        14\n",
      "        1898       0.13      0.44      0.20         9\n",
      "        1899       0.06      0.50      0.11         2\n",
      "        1900       0.22      0.73      0.34       179\n",
      "        1901       0.07      0.14      0.09         7\n",
      "        1902       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.23      0.73      0.35     80391\n",
      "   macro avg       0.13      0.39      0.19     80391\n",
      "weighted avg       0.32      0.73      0.42     80391\n",
      " samples avg       0.29      0.73      0.40     80391\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "print(\"Accuracy :\",metrics.accuracy_score(y_test_multilabel, predictions))\n",
    "print(\"Hamming loss \",metrics.hamming_loss(y_test_multilabel,predictions))\n",
    "precision = precision_score(y_test_multilabel, predictions, average='micro')\n",
    "recall = recall_score(y_test_multilabel, predictions, average='micro')\n",
    "f1 = f1_score(y_test_multilabel, predictions, average='micro')\n",
    " \n",
    "print(\"\\nMicro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "precision = precision_score(y_test_multilabel, predictions, average='macro')\n",
    "recall = recall_score(y_test_multilabel, predictions, average='macro')\n",
    "f1 = f1_score(y_test_multilabel, predictions, average='macro')\n",
    " \n",
    "print(\"\\nMacro-average quality numbers\")\n",
    "print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "print(\"\\nClassification Report\")\n",
    "print (metrics.classification_report(y_test_multilabel, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is', 'the', 'this']\n"
     ]
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "vectorizer = CountVectorizer(binary='true', max_features=3)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Binary Relevance:\n",
    "Transformer un problème multi-label avec K étiquettes en des problèmes de classification binaire séparés. Chaque classificateur prédit si une étiquette est présente ou non.\n",
    "\n",
    "Les deux techniques présentées en haut traitent le problème multi-label (choix multiples) en une série de questions oui/non, mais la dernière traite des choix mutuellement exclusifs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Classifier Chains:\n",
    "Un classificateur 1 sera formé sur les données d'entrée. La sortie du classificateur 1 sera alimentée en entrée pour le classificateur 2, qui prédit la deuxième étiquette, la sortie du classificateur 2 sera alimentée en entrée pour le classificateur 3 et ainsi de suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.modules['sklearn.externals.joblib'] = joblib\n",
    "\n",
    "from skmultilearn.embedding import OpenNetworkEmbedder\n",
    "from skmultilearn.cluster import LabelCooccurrenceGraphBuilder\n",
    "\n",
    "\n",
    "graph_builder = LabelCooccurrenceGraphBuilder(weighted=True, include_self_edges=False)\n",
    "openne_line_params = dict(batch_size=1000, order=3)\n",
    "embedder = OpenNetworkEmbedder(\n",
    "    graph_builder,\n",
    "    'LINE',\n",
    "    dimension = 5*df_cleaned_3.iloc[:, 5:].values.shape[1],\n",
    "    aggregation_function = 'add',\n",
    "    normalize_weights=True,\n",
    "    param_dict = openne_line_params\n",
    ")\n",
    "from skmultilearn.embedding import EmbeddingClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from skmultilearn.adapt import MLkNN\n",
    "\n",
    "\n",
    "clf = EmbeddingClassifier(\n",
    "    embedder,\n",
    "    RandomForestRegressor(n_estimators=10),\n",
    "    MLkNN(k=5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-procesing for non-uniform negative sampling!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'contrib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-74c648607d1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_multilabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skmultilearn\\embedding\\classifier.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_input_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m         \u001b[0my_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[0mX_y_embedded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_concatenate_matrices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_embedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skmultilearn\\embedding\\openne.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[0mparam_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'graph'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mparam_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdimension_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 143\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    144\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_embedd_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\amine\\onedrive\\bureau\\git\\openne\\src\\openne\\line.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, rep_size, batch_size, epoch, negative_ratio, order, label_file, clf_ratio, auto_save)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0morder\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m             self.model1 = _LINE(graph, rep_size/2, batch_size,\n\u001b[0m\u001b[0;32m    210\u001b[0m                                 negative_ratio, order=1)\n\u001b[0;32m    211\u001b[0m             self.model2 = _LINE(graph, rep_size/2, batch_size,\n",
      "\u001b[1;32mc:\\users\\amine\\onedrive\\bureau\\git\\openne\\src\\openne\\line.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, rep_size, batch_size, negative_ratio, order)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mcur_seed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetrandbits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         initializer = tf.contrib.layers.xavier_initializer(\n\u001b[0m\u001b[0;32m     25\u001b[0m             uniform=False, seed=cur_seed)\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'contrib'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "\n",
    "clf.fit(X_train_multilabel, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = clf.predict(X_test_multilabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trois approches peuvent etre prises pour la colonne sous_domaine:\n",
    "- La prétraiter (enlever les www et les lettres, tokenizer...) et l'ajouter à la colonne path pour former une description\n",
    "- L'enlever \n",
    "- La prétraiter afin de construire une feature catégorielle.\n",
    "- Construire directement une feature catégorielle sans prétraitement\n",
    "\n",
    "Pour l'instant nous optons pour la 2eme approche"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
